{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DACON Stage1 반도체 박막 두께 분석 알고리즘 대회.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WonJunPark/Semiconductor_Thin_Film_Analysis/blob/master/DACON_Stage1_%EB%B0%98%EB%8F%84%EC%B2%B4_%EB%B0%95%EB%A7%89_%EB%91%90%EA%BB%98_%EB%B6%84%EC%84%9D_%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98_%EB%8C%80%ED%9A%8C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VuT7lky2F9-S",
        "colab_type": "text"
      },
      "source": [
        "DACON Stage1 반도체 박막 두께 분석 알고리즘 대회"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwQrxW0SGxky",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRPeA3LmF8vL",
        "colab_type": "code",
        "outputId": "4bf844f7-6dd3-4715-d4e0-956ab9edfd5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmaS2NnwGY6y",
        "colab_type": "code",
        "outputId": "e1852b2f-3aae-4687-a7cf-f11b6e7d0895",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "!ls \"/content/gdrive/My Drive/semiconductor"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: -c: line 0: unexpected EOF while looking for matching `\"'\n",
            "/bin/bash: -c: line 1: syntax error: unexpected end of file\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjodPEv4GaRW",
        "colab_type": "code",
        "outputId": "05fbacfb-07b5-4979-e11b-8d89c41da88a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd /content/gdrive/My Drive/semiconductor"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/semiconductor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BR37By5hGaTn",
        "colab_type": "code",
        "outputId": "3764fae0-b75b-4f07-a227-4e22abd51e91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "source": [
        "train = pd.read_csv(\"train.csv\")\n",
        "train.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>layer_1</th>\n",
              "      <th>layer_2</th>\n",
              "      <th>layer_3</th>\n",
              "      <th>layer_4</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>...</th>\n",
              "      <th>186</th>\n",
              "      <th>187</th>\n",
              "      <th>188</th>\n",
              "      <th>189</th>\n",
              "      <th>190</th>\n",
              "      <th>191</th>\n",
              "      <th>192</th>\n",
              "      <th>193</th>\n",
              "      <th>194</th>\n",
              "      <th>195</th>\n",
              "      <th>196</th>\n",
              "      <th>197</th>\n",
              "      <th>198</th>\n",
              "      <th>199</th>\n",
              "      <th>200</th>\n",
              "      <th>201</th>\n",
              "      <th>202</th>\n",
              "      <th>203</th>\n",
              "      <th>204</th>\n",
              "      <th>205</th>\n",
              "      <th>206</th>\n",
              "      <th>207</th>\n",
              "      <th>208</th>\n",
              "      <th>209</th>\n",
              "      <th>210</th>\n",
              "      <th>211</th>\n",
              "      <th>212</th>\n",
              "      <th>213</th>\n",
              "      <th>214</th>\n",
              "      <th>215</th>\n",
              "      <th>216</th>\n",
              "      <th>217</th>\n",
              "      <th>218</th>\n",
              "      <th>219</th>\n",
              "      <th>220</th>\n",
              "      <th>221</th>\n",
              "      <th>222</th>\n",
              "      <th>223</th>\n",
              "      <th>224</th>\n",
              "      <th>225</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>0.254551</td>\n",
              "      <td>0.258823</td>\n",
              "      <td>0.254659</td>\n",
              "      <td>0.252085</td>\n",
              "      <td>0.247678</td>\n",
              "      <td>0.253614</td>\n",
              "      <td>0.246511</td>\n",
              "      <td>0.259407</td>\n",
              "      <td>0.260862</td>\n",
              "      <td>0.242524</td>\n",
              "      <td>0.253870</td>\n",
              "      <td>0.245156</td>\n",
              "      <td>0.245548</td>\n",
              "      <td>0.255501</td>\n",
              "      <td>0.228948</td>\n",
              "      <td>0.228632</td>\n",
              "      <td>0.225802</td>\n",
              "      <td>0.249418</td>\n",
              "      <td>0.246910</td>\n",
              "      <td>0.248747</td>\n",
              "      <td>0.251088</td>\n",
              "      <td>0.244886</td>\n",
              "      <td>0.233906</td>\n",
              "      <td>0.242632</td>\n",
              "      <td>0.221792</td>\n",
              "      <td>0.236521</td>\n",
              "      <td>0.220555</td>\n",
              "      <td>0.243761</td>\n",
              "      <td>0.230202</td>\n",
              "      <td>0.226122</td>\n",
              "      <td>0.220671</td>\n",
              "      <td>0.235075</td>\n",
              "      <td>0.224560</td>\n",
              "      <td>0.226998</td>\n",
              "      <td>0.209499</td>\n",
              "      <td>0.226594</td>\n",
              "      <td>...</td>\n",
              "      <td>0.160126</td>\n",
              "      <td>0.164192</td>\n",
              "      <td>0.171406</td>\n",
              "      <td>0.162364</td>\n",
              "      <td>0.168591</td>\n",
              "      <td>0.166626</td>\n",
              "      <td>0.169696</td>\n",
              "      <td>0.196383</td>\n",
              "      <td>0.194145</td>\n",
              "      <td>0.190646</td>\n",
              "      <td>0.186797</td>\n",
              "      <td>0.191748</td>\n",
              "      <td>0.190886</td>\n",
              "      <td>0.208518</td>\n",
              "      <td>0.211220</td>\n",
              "      <td>0.229286</td>\n",
              "      <td>0.226265</td>\n",
              "      <td>0.226954</td>\n",
              "      <td>0.229023</td>\n",
              "      <td>0.237112</td>\n",
              "      <td>0.262421</td>\n",
              "      <td>0.262566</td>\n",
              "      <td>0.272062</td>\n",
              "      <td>0.292049</td>\n",
              "      <td>0.305353</td>\n",
              "      <td>0.292889</td>\n",
              "      <td>0.317479</td>\n",
              "      <td>0.316911</td>\n",
              "      <td>0.321371</td>\n",
              "      <td>0.355636</td>\n",
              "      <td>0.354750</td>\n",
              "      <td>0.369223</td>\n",
              "      <td>0.388184</td>\n",
              "      <td>0.408496</td>\n",
              "      <td>0.414564</td>\n",
              "      <td>0.429403</td>\n",
              "      <td>0.419225</td>\n",
              "      <td>0.443250</td>\n",
              "      <td>0.433414</td>\n",
              "      <td>0.465502</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>20</td>\n",
              "      <td>0.205062</td>\n",
              "      <td>0.225544</td>\n",
              "      <td>0.217758</td>\n",
              "      <td>0.202169</td>\n",
              "      <td>0.199633</td>\n",
              "      <td>0.207380</td>\n",
              "      <td>0.191318</td>\n",
              "      <td>0.195369</td>\n",
              "      <td>0.200536</td>\n",
              "      <td>0.197588</td>\n",
              "      <td>0.198726</td>\n",
              "      <td>0.191803</td>\n",
              "      <td>0.199625</td>\n",
              "      <td>0.206465</td>\n",
              "      <td>0.182836</td>\n",
              "      <td>0.193341</td>\n",
              "      <td>0.180459</td>\n",
              "      <td>0.196416</td>\n",
              "      <td>0.185398</td>\n",
              "      <td>0.188913</td>\n",
              "      <td>0.176011</td>\n",
              "      <td>0.173457</td>\n",
              "      <td>0.182249</td>\n",
              "      <td>0.176816</td>\n",
              "      <td>0.192716</td>\n",
              "      <td>0.185924</td>\n",
              "      <td>0.183816</td>\n",
              "      <td>0.186900</td>\n",
              "      <td>0.161040</td>\n",
              "      <td>0.173525</td>\n",
              "      <td>0.172948</td>\n",
              "      <td>0.182634</td>\n",
              "      <td>0.161153</td>\n",
              "      <td>0.158073</td>\n",
              "      <td>0.152335</td>\n",
              "      <td>0.148293</td>\n",
              "      <td>...</td>\n",
              "      <td>0.327076</td>\n",
              "      <td>0.331195</td>\n",
              "      <td>0.337722</td>\n",
              "      <td>0.340189</td>\n",
              "      <td>0.342748</td>\n",
              "      <td>0.351925</td>\n",
              "      <td>0.372989</td>\n",
              "      <td>0.389663</td>\n",
              "      <td>0.396216</td>\n",
              "      <td>0.384977</td>\n",
              "      <td>0.383701</td>\n",
              "      <td>0.403894</td>\n",
              "      <td>0.406382</td>\n",
              "      <td>0.429342</td>\n",
              "      <td>0.409908</td>\n",
              "      <td>0.439307</td>\n",
              "      <td>0.432569</td>\n",
              "      <td>0.439114</td>\n",
              "      <td>0.459541</td>\n",
              "      <td>0.454988</td>\n",
              "      <td>0.475268</td>\n",
              "      <td>0.478575</td>\n",
              "      <td>0.483466</td>\n",
              "      <td>0.496912</td>\n",
              "      <td>0.499542</td>\n",
              "      <td>0.522705</td>\n",
              "      <td>0.524767</td>\n",
              "      <td>0.533952</td>\n",
              "      <td>0.558729</td>\n",
              "      <td>0.572470</td>\n",
              "      <td>0.557203</td>\n",
              "      <td>0.573656</td>\n",
              "      <td>0.587998</td>\n",
              "      <td>0.612754</td>\n",
              "      <td>0.627825</td>\n",
              "      <td>0.633393</td>\n",
              "      <td>0.637706</td>\n",
              "      <td>0.625981</td>\n",
              "      <td>0.653231</td>\n",
              "      <td>0.637853</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>30</td>\n",
              "      <td>0.189196</td>\n",
              "      <td>0.165869</td>\n",
              "      <td>0.177655</td>\n",
              "      <td>0.156822</td>\n",
              "      <td>0.175094</td>\n",
              "      <td>0.177755</td>\n",
              "      <td>0.157582</td>\n",
              "      <td>0.158885</td>\n",
              "      <td>0.156911</td>\n",
              "      <td>0.166162</td>\n",
              "      <td>0.148831</td>\n",
              "      <td>0.144950</td>\n",
              "      <td>0.151362</td>\n",
              "      <td>0.145110</td>\n",
              "      <td>0.159201</td>\n",
              "      <td>0.139296</td>\n",
              "      <td>0.145313</td>\n",
              "      <td>0.156555</td>\n",
              "      <td>0.145363</td>\n",
              "      <td>0.150352</td>\n",
              "      <td>0.150542</td>\n",
              "      <td>0.142990</td>\n",
              "      <td>0.139572</td>\n",
              "      <td>0.145669</td>\n",
              "      <td>0.144514</td>\n",
              "      <td>0.126263</td>\n",
              "      <td>0.112832</td>\n",
              "      <td>0.117535</td>\n",
              "      <td>0.111473</td>\n",
              "      <td>0.117545</td>\n",
              "      <td>0.107058</td>\n",
              "      <td>0.119299</td>\n",
              "      <td>0.110768</td>\n",
              "      <td>0.124217</td>\n",
              "      <td>0.124496</td>\n",
              "      <td>0.110023</td>\n",
              "      <td>...</td>\n",
              "      <td>0.525450</td>\n",
              "      <td>0.532645</td>\n",
              "      <td>0.539097</td>\n",
              "      <td>0.527091</td>\n",
              "      <td>0.531925</td>\n",
              "      <td>0.530325</td>\n",
              "      <td>0.551716</td>\n",
              "      <td>0.556125</td>\n",
              "      <td>0.567470</td>\n",
              "      <td>0.549711</td>\n",
              "      <td>0.566789</td>\n",
              "      <td>0.574313</td>\n",
              "      <td>0.569873</td>\n",
              "      <td>0.574390</td>\n",
              "      <td>0.601672</td>\n",
              "      <td>0.584206</td>\n",
              "      <td>0.602981</td>\n",
              "      <td>0.598708</td>\n",
              "      <td>0.615189</td>\n",
              "      <td>0.637023</td>\n",
              "      <td>0.626458</td>\n",
              "      <td>0.645439</td>\n",
              "      <td>0.629203</td>\n",
              "      <td>0.640967</td>\n",
              "      <td>0.652762</td>\n",
              "      <td>0.660495</td>\n",
              "      <td>0.676498</td>\n",
              "      <td>0.674599</td>\n",
              "      <td>0.693535</td>\n",
              "      <td>0.699182</td>\n",
              "      <td>0.699864</td>\n",
              "      <td>0.708688</td>\n",
              "      <td>0.721982</td>\n",
              "      <td>0.713464</td>\n",
              "      <td>0.743030</td>\n",
              "      <td>0.741709</td>\n",
              "      <td>0.747743</td>\n",
              "      <td>0.746037</td>\n",
              "      <td>0.737356</td>\n",
              "      <td>0.750391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>40</td>\n",
              "      <td>0.131003</td>\n",
              "      <td>0.120076</td>\n",
              "      <td>0.138975</td>\n",
              "      <td>0.117931</td>\n",
              "      <td>0.130566</td>\n",
              "      <td>0.131262</td>\n",
              "      <td>0.126962</td>\n",
              "      <td>0.134453</td>\n",
              "      <td>0.106717</td>\n",
              "      <td>0.127309</td>\n",
              "      <td>0.099958</td>\n",
              "      <td>0.112908</td>\n",
              "      <td>0.106853</td>\n",
              "      <td>0.108288</td>\n",
              "      <td>0.101393</td>\n",
              "      <td>0.094074</td>\n",
              "      <td>0.086854</td>\n",
              "      <td>0.099669</td>\n",
              "      <td>0.107276</td>\n",
              "      <td>0.091117</td>\n",
              "      <td>0.084525</td>\n",
              "      <td>0.078293</td>\n",
              "      <td>0.076476</td>\n",
              "      <td>0.078559</td>\n",
              "      <td>0.072960</td>\n",
              "      <td>0.075898</td>\n",
              "      <td>0.067963</td>\n",
              "      <td>0.066055</td>\n",
              "      <td>0.087904</td>\n",
              "      <td>0.065373</td>\n",
              "      <td>0.075469</td>\n",
              "      <td>0.080097</td>\n",
              "      <td>0.068895</td>\n",
              "      <td>0.058148</td>\n",
              "      <td>0.057882</td>\n",
              "      <td>0.063258</td>\n",
              "      <td>...</td>\n",
              "      <td>0.616934</td>\n",
              "      <td>0.638654</td>\n",
              "      <td>0.630914</td>\n",
              "      <td>0.647135</td>\n",
              "      <td>0.629796</td>\n",
              "      <td>0.644114</td>\n",
              "      <td>0.641825</td>\n",
              "      <td>0.645360</td>\n",
              "      <td>0.653030</td>\n",
              "      <td>0.656335</td>\n",
              "      <td>0.657734</td>\n",
              "      <td>0.678019</td>\n",
              "      <td>0.676713</td>\n",
              "      <td>0.681540</td>\n",
              "      <td>0.673333</td>\n",
              "      <td>0.686743</td>\n",
              "      <td>0.697500</td>\n",
              "      <td>0.702650</td>\n",
              "      <td>0.693750</td>\n",
              "      <td>0.711013</td>\n",
              "      <td>0.714411</td>\n",
              "      <td>0.701010</td>\n",
              "      <td>0.726972</td>\n",
              "      <td>0.719394</td>\n",
              "      <td>0.726329</td>\n",
              "      <td>0.730821</td>\n",
              "      <td>0.740062</td>\n",
              "      <td>0.747356</td>\n",
              "      <td>0.749405</td>\n",
              "      <td>0.766173</td>\n",
              "      <td>0.764786</td>\n",
              "      <td>0.763788</td>\n",
              "      <td>0.770017</td>\n",
              "      <td>0.787571</td>\n",
              "      <td>0.778866</td>\n",
              "      <td>0.776969</td>\n",
              "      <td>0.774712</td>\n",
              "      <td>0.801526</td>\n",
              "      <td>0.805305</td>\n",
              "      <td>0.784057</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>50</td>\n",
              "      <td>0.091033</td>\n",
              "      <td>0.086893</td>\n",
              "      <td>0.108125</td>\n",
              "      <td>0.080405</td>\n",
              "      <td>0.105917</td>\n",
              "      <td>0.077083</td>\n",
              "      <td>0.097895</td>\n",
              "      <td>0.086765</td>\n",
              "      <td>0.078676</td>\n",
              "      <td>0.075729</td>\n",
              "      <td>0.086023</td>\n",
              "      <td>0.070649</td>\n",
              "      <td>0.078957</td>\n",
              "      <td>0.072772</td>\n",
              "      <td>0.069867</td>\n",
              "      <td>0.080523</td>\n",
              "      <td>0.068273</td>\n",
              "      <td>0.074660</td>\n",
              "      <td>0.069852</td>\n",
              "      <td>0.047442</td>\n",
              "      <td>0.067855</td>\n",
              "      <td>0.049580</td>\n",
              "      <td>0.068737</td>\n",
              "      <td>0.041386</td>\n",
              "      <td>0.048697</td>\n",
              "      <td>0.040278</td>\n",
              "      <td>0.050234</td>\n",
              "      <td>0.059371</td>\n",
              "      <td>0.042581</td>\n",
              "      <td>0.037117</td>\n",
              "      <td>0.041503</td>\n",
              "      <td>0.055113</td>\n",
              "      <td>0.034001</td>\n",
              "      <td>0.035846</td>\n",
              "      <td>0.030385</td>\n",
              "      <td>0.048935</td>\n",
              "      <td>...</td>\n",
              "      <td>0.670888</td>\n",
              "      <td>0.692846</td>\n",
              "      <td>0.673025</td>\n",
              "      <td>0.704448</td>\n",
              "      <td>0.696657</td>\n",
              "      <td>0.697524</td>\n",
              "      <td>0.692513</td>\n",
              "      <td>0.714224</td>\n",
              "      <td>0.696880</td>\n",
              "      <td>0.716361</td>\n",
              "      <td>0.723607</td>\n",
              "      <td>0.720018</td>\n",
              "      <td>0.715039</td>\n",
              "      <td>0.705079</td>\n",
              "      <td>0.720913</td>\n",
              "      <td>0.723440</td>\n",
              "      <td>0.719858</td>\n",
              "      <td>0.729948</td>\n",
              "      <td>0.731360</td>\n",
              "      <td>0.728861</td>\n",
              "      <td>0.740501</td>\n",
              "      <td>0.738362</td>\n",
              "      <td>0.749341</td>\n",
              "      <td>0.738456</td>\n",
              "      <td>0.768791</td>\n",
              "      <td>0.770292</td>\n",
              "      <td>0.766630</td>\n",
              "      <td>0.779970</td>\n",
              "      <td>0.787695</td>\n",
              "      <td>0.766521</td>\n",
              "      <td>0.786677</td>\n",
              "      <td>0.802271</td>\n",
              "      <td>0.806557</td>\n",
              "      <td>0.799614</td>\n",
              "      <td>0.789333</td>\n",
              "      <td>0.804087</td>\n",
              "      <td>0.787763</td>\n",
              "      <td>0.794948</td>\n",
              "      <td>0.819105</td>\n",
              "      <td>0.801781</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 230 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   layer_1  layer_2  layer_3  layer_4  ...       222       223       224       225\n",
              "0       10       10       10       10  ...  0.419225  0.443250  0.433414  0.465502\n",
              "1       10       10       10       20  ...  0.637706  0.625981  0.653231  0.637853\n",
              "2       10       10       10       30  ...  0.747743  0.746037  0.737356  0.750391\n",
              "3       10       10       10       40  ...  0.774712  0.801526  0.805305  0.784057\n",
              "4       10       10       10       50  ...  0.787763  0.794948  0.819105  0.801781\n",
              "\n",
              "[5 rows x 230 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgpZT_-a510a",
        "colab_type": "code",
        "outputId": "4a144c5f-947f-4f8b-de90-1f7a6d15afdc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(train)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "810000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0BX-UumGaV9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Test 데이터를 불러옵니다.\n",
        "test = pd.read_csv('test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4nAFknTG9hL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#독립변수와 종속변수를 분리합니다.\n",
        "train_X = train.iloc[:,4:]  #Train 데이터의 독립변수\n",
        "train_Y = train.iloc[:,0:4] #Train 데이터의 종속변수\n",
        "test_X = test.iloc[:,1:]    #Test  데이터의 독립변수"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxW6e_yxGt5h",
        "colab_type": "text"
      },
      "source": [
        "# 차원 축소 (PCA)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPoO1RM_GtSN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1ij11RjIgvs",
        "colab_type": "code",
        "outputId": "23dda542-31fa-4f59-ab53-38990865211b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(train_X),len(test_X))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "810000 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4Fx8ttVIqLA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = pd.concat([train_X,test_X])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srFRZfO6I1r2",
        "colab_type": "code",
        "outputId": "c97ecb09-a7ef-4bb9-f601-7faf4419a0dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(X)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "820000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tpuhupx9GtVn",
        "colab_type": "code",
        "outputId": "4478148b-3d3b-443e-a671-d067f711f9cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "  #주성분 추출\n",
        "  pca = PCA() \n",
        "  pca.fit(X)\n",
        "  cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
        "  d = np.argmax(cumsum >= 0.99)+1\n",
        "  print(\"분산을 99%로 유지시켜주는 차원 :\",d)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "분산을 70%로 유지시켜주는 차원 : 27\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bL-RF4IRHJ9e",
        "colab_type": "code",
        "outputId": "ed90745d-e18e-4632-c6e7-17e83ee1e5c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pca = PCA(n_components= 27)\n",
        "\n",
        "train_X_pca = pca.fit_transform(train_X)\n",
        "test_X_pca = pca.fit_transform(test_X)\n",
        "\n",
        "print(train_X_pca.shape, test_X_pca.shape)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(810000, 27) (10000, 27)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjnHyN_q0fJo",
        "colab_type": "text"
      },
      "source": [
        "# test report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghIlw0SIvkF1",
        "colab_type": "text"
      },
      "source": [
        "1/13\n",
        "첫번째 시도.\n",
        "\n",
        "모델 3층\n",
        "\n",
        "score : 54.2431\n",
        "\n",
        "------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3nyojnwvnli",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "두번째 시도. \n",
        "\n",
        "모델 6층 \n",
        "\n",
        "score : 58.5697\n",
        "\n",
        "-----------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtSF7aapvsjw",
        "colab_type": "text"
      },
      "source": [
        "세번째 시도.\n",
        "\n",
        "모델 6층/ epochs 200\n",
        "\n",
        "특이사항 : 137회에서 오버피팅\n",
        "\n",
        "score : 40.1392\n",
        "\n",
        "----------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgwo7MJsz_yG",
        "colab_type": "text"
      },
      "source": [
        "1/14\n",
        "네번째 시도.\n",
        "\n",
        "모델 6층/ dropout 0.5추가/ epochs 200\n",
        "\n",
        "특이사항 : 10회에서 오버피팅\n",
        "\n",
        "score : 44.2593\n",
        "\n",
        "----------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a34Vv0OH2Ury",
        "colab_type": "text"
      },
      "source": [
        "다섯번째 시도.\n",
        "\n",
        "모델 6층/ l1,l2 규제 추가/ epochs 200\n",
        "\n",
        "특이사항 : 꾸준히 내려감, 추후 epochs 늘려볼 것 // mse 55\n",
        "\n",
        "score : 45.0394\n",
        "\n",
        "----------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJv_FGbl3e66",
        "colab_type": "text"
      },
      "source": [
        "여섯번째 시도.\n",
        "\n",
        "모델 6층/ dropout 0.5/ l1,l2 규제 추가/ epochs 300\n",
        "\n",
        "특이사항 : 꾸준히 내려감 역시 mse 55\n",
        "\n",
        "score : 35.1845\n",
        "\n",
        "----------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cS4rVSqs5k6b",
        "colab_type": "text"
      },
      "source": [
        "일곱번째 시도.\n",
        "\n",
        "PCA를 사용해봄\n",
        "모델 간소화\n",
        "차원 : 18\n",
        "\n",
        "특이사항 : @\n",
        "\n",
        "score : 159.403\n",
        "\n",
        "----------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhOXCnPPV6-O",
        "colab_type": "text"
      },
      "source": [
        "여덟번째 시도.\n",
        "\n",
        "PCA를 사용해봄\n",
        "모델 간소화\n",
        "차원 : 27\n",
        "에포크 1000\n",
        "\n",
        "특이사항 : @\n",
        "\n",
        "score : 158\n",
        "\n",
        "----------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kaqZyfU0kZ4",
        "colab_type": "text"
      },
      "source": [
        "# model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsdKJGbR32aP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#케라스를 통해 모델 생성을 시작합니다.\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "model = Sequential()\n",
        "model.add(Dense(units=16, activation='relu', input_dim=27))\n",
        "model.add(Dense(units=8, activation='relu'))\n",
        "model.add(Dense(units=4, activation='linear'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziH0MDXjKKJ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer = 'RMSProp',\n",
        "              loss='mae',\n",
        "              metrics=['mae'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIWKxpRIKUWW",
        "colab_type": "code",
        "outputId": "803788e8-240f-4896-9c1e-4d83a3d9b1fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit(train_X_pca,\n",
        "                    train_Y,\n",
        "                    epochs = 1000,\n",
        "                    batch_size = 10000,\n",
        "                    validation_split = 0.05)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 769500 samples, validate on 40500 samples\n",
            "Epoch 1/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 53.0279 - mean_absolute_error: 53.0279 - val_loss: 66.0243 - val_mean_absolute_error: 66.0243\n",
            "Epoch 2/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 53.0200 - mean_absolute_error: 53.0200 - val_loss: 65.8035 - val_mean_absolute_error: 65.8035\n",
            "Epoch 3/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 53.0114 - mean_absolute_error: 53.0114 - val_loss: 66.0561 - val_mean_absolute_error: 66.0561\n",
            "Epoch 4/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 53.0035 - mean_absolute_error: 53.0035 - val_loss: 65.8988 - val_mean_absolute_error: 65.8988\n",
            "Epoch 5/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.9954 - mean_absolute_error: 52.9954 - val_loss: 65.9854 - val_mean_absolute_error: 65.9854\n",
            "Epoch 6/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.9876 - mean_absolute_error: 52.9876 - val_loss: 66.0016 - val_mean_absolute_error: 66.0016\n",
            "Epoch 7/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.9794 - mean_absolute_error: 52.9794 - val_loss: 65.9847 - val_mean_absolute_error: 65.9847\n",
            "Epoch 8/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.9716 - mean_absolute_error: 52.9716 - val_loss: 65.7827 - val_mean_absolute_error: 65.7827\n",
            "Epoch 9/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.9646 - mean_absolute_error: 52.9646 - val_loss: 65.7232 - val_mean_absolute_error: 65.7232\n",
            "Epoch 10/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.9577 - mean_absolute_error: 52.9577 - val_loss: 65.7861 - val_mean_absolute_error: 65.7861\n",
            "Epoch 11/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.9508 - mean_absolute_error: 52.9508 - val_loss: 65.8147 - val_mean_absolute_error: 65.8147\n",
            "Epoch 12/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.9442 - mean_absolute_error: 52.9442 - val_loss: 65.7803 - val_mean_absolute_error: 65.7803\n",
            "Epoch 13/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.9377 - mean_absolute_error: 52.9377 - val_loss: 65.7619 - val_mean_absolute_error: 65.7619\n",
            "Epoch 14/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.9314 - mean_absolute_error: 52.9314 - val_loss: 65.8772 - val_mean_absolute_error: 65.8772\n",
            "Epoch 15/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.9247 - mean_absolute_error: 52.9247 - val_loss: 65.7513 - val_mean_absolute_error: 65.7513\n",
            "Epoch 16/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.9185 - mean_absolute_error: 52.9185 - val_loss: 65.6840 - val_mean_absolute_error: 65.6840\n",
            "Epoch 17/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.9131 - mean_absolute_error: 52.9131 - val_loss: 65.9687 - val_mean_absolute_error: 65.9687\n",
            "Epoch 18/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.9066 - mean_absolute_error: 52.9066 - val_loss: 66.0083 - val_mean_absolute_error: 66.0083\n",
            "Epoch 19/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.9015 - mean_absolute_error: 52.9015 - val_loss: 65.6875 - val_mean_absolute_error: 65.6875\n",
            "Epoch 20/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.8961 - mean_absolute_error: 52.8961 - val_loss: 65.8583 - val_mean_absolute_error: 65.8583\n",
            "Epoch 21/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.8902 - mean_absolute_error: 52.8902 - val_loss: 65.7200 - val_mean_absolute_error: 65.7200\n",
            "Epoch 22/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.8845 - mean_absolute_error: 52.8845 - val_loss: 65.6086 - val_mean_absolute_error: 65.6086\n",
            "Epoch 23/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.8795 - mean_absolute_error: 52.8795 - val_loss: 65.6360 - val_mean_absolute_error: 65.6360\n",
            "Epoch 24/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.8740 - mean_absolute_error: 52.8740 - val_loss: 65.6369 - val_mean_absolute_error: 65.6369\n",
            "Epoch 25/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.8685 - mean_absolute_error: 52.8685 - val_loss: 65.7310 - val_mean_absolute_error: 65.7310\n",
            "Epoch 26/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.8634 - mean_absolute_error: 52.8634 - val_loss: 65.9089 - val_mean_absolute_error: 65.9089\n",
            "Epoch 27/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.8580 - mean_absolute_error: 52.8580 - val_loss: 65.8589 - val_mean_absolute_error: 65.8589\n",
            "Epoch 28/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.8526 - mean_absolute_error: 52.8526 - val_loss: 65.5663 - val_mean_absolute_error: 65.5663\n",
            "Epoch 29/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.8472 - mean_absolute_error: 52.8472 - val_loss: 65.6489 - val_mean_absolute_error: 65.6489\n",
            "Epoch 30/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.8423 - mean_absolute_error: 52.8423 - val_loss: 65.6673 - val_mean_absolute_error: 65.6673\n",
            "Epoch 31/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.8368 - mean_absolute_error: 52.8368 - val_loss: 65.4433 - val_mean_absolute_error: 65.4433\n",
            "Epoch 32/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.8315 - mean_absolute_error: 52.8315 - val_loss: 65.9309 - val_mean_absolute_error: 65.9309\n",
            "Epoch 33/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.8262 - mean_absolute_error: 52.8262 - val_loss: 65.7339 - val_mean_absolute_error: 65.7339\n",
            "Epoch 34/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.8205 - mean_absolute_error: 52.8205 - val_loss: 65.7742 - val_mean_absolute_error: 65.7742\n",
            "Epoch 35/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.8153 - mean_absolute_error: 52.8153 - val_loss: 65.7659 - val_mean_absolute_error: 65.7659\n",
            "Epoch 36/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.8102 - mean_absolute_error: 52.8102 - val_loss: 65.7467 - val_mean_absolute_error: 65.7467\n",
            "Epoch 37/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.8045 - mean_absolute_error: 52.8045 - val_loss: 65.6007 - val_mean_absolute_error: 65.6007\n",
            "Epoch 38/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.7991 - mean_absolute_error: 52.7991 - val_loss: 65.8711 - val_mean_absolute_error: 65.8711\n",
            "Epoch 39/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.7935 - mean_absolute_error: 52.7935 - val_loss: 65.8322 - val_mean_absolute_error: 65.8322\n",
            "Epoch 40/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.7876 - mean_absolute_error: 52.7876 - val_loss: 65.7523 - val_mean_absolute_error: 65.7523\n",
            "Epoch 41/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.7819 - mean_absolute_error: 52.7819 - val_loss: 65.7756 - val_mean_absolute_error: 65.7756\n",
            "Epoch 42/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.7760 - mean_absolute_error: 52.7760 - val_loss: 65.8083 - val_mean_absolute_error: 65.8083\n",
            "Epoch 43/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.7702 - mean_absolute_error: 52.7702 - val_loss: 65.7422 - val_mean_absolute_error: 65.7422\n",
            "Epoch 44/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.7643 - mean_absolute_error: 52.7643 - val_loss: 65.9057 - val_mean_absolute_error: 65.9057\n",
            "Epoch 45/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.7585 - mean_absolute_error: 52.7585 - val_loss: 65.7108 - val_mean_absolute_error: 65.7108\n",
            "Epoch 46/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.7523 - mean_absolute_error: 52.7523 - val_loss: 65.6860 - val_mean_absolute_error: 65.6860\n",
            "Epoch 47/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.7462 - mean_absolute_error: 52.7462 - val_loss: 65.8055 - val_mean_absolute_error: 65.8055\n",
            "Epoch 48/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.7402 - mean_absolute_error: 52.7402 - val_loss: 65.6657 - val_mean_absolute_error: 65.6657\n",
            "Epoch 49/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.7343 - mean_absolute_error: 52.7343 - val_loss: 65.7697 - val_mean_absolute_error: 65.7697\n",
            "Epoch 50/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.7279 - mean_absolute_error: 52.7279 - val_loss: 65.6258 - val_mean_absolute_error: 65.6258\n",
            "Epoch 51/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.7214 - mean_absolute_error: 52.7214 - val_loss: 65.5728 - val_mean_absolute_error: 65.5728\n",
            "Epoch 52/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.7149 - mean_absolute_error: 52.7149 - val_loss: 65.9085 - val_mean_absolute_error: 65.9085\n",
            "Epoch 53/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.7086 - mean_absolute_error: 52.7086 - val_loss: 65.6328 - val_mean_absolute_error: 65.6328\n",
            "Epoch 54/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.7018 - mean_absolute_error: 52.7018 - val_loss: 65.8235 - val_mean_absolute_error: 65.8235\n",
            "Epoch 55/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.6955 - mean_absolute_error: 52.6955 - val_loss: 65.6285 - val_mean_absolute_error: 65.6285\n",
            "Epoch 56/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.6885 - mean_absolute_error: 52.6885 - val_loss: 65.7872 - val_mean_absolute_error: 65.7872\n",
            "Epoch 57/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.6820 - mean_absolute_error: 52.6820 - val_loss: 65.7880 - val_mean_absolute_error: 65.7880\n",
            "Epoch 58/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.6748 - mean_absolute_error: 52.6748 - val_loss: 65.7392 - val_mean_absolute_error: 65.7392\n",
            "Epoch 59/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.6680 - mean_absolute_error: 52.6680 - val_loss: 65.6645 - val_mean_absolute_error: 65.6645\n",
            "Epoch 60/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.6610 - mean_absolute_error: 52.6610 - val_loss: 65.5674 - val_mean_absolute_error: 65.5674\n",
            "Epoch 61/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.6535 - mean_absolute_error: 52.6535 - val_loss: 65.6424 - val_mean_absolute_error: 65.6424\n",
            "Epoch 62/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.6469 - mean_absolute_error: 52.6469 - val_loss: 65.8100 - val_mean_absolute_error: 65.8100\n",
            "Epoch 63/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.6396 - mean_absolute_error: 52.6396 - val_loss: 65.7893 - val_mean_absolute_error: 65.7893\n",
            "Epoch 64/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.6324 - mean_absolute_error: 52.6324 - val_loss: 65.7728 - val_mean_absolute_error: 65.7728\n",
            "Epoch 65/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.6251 - mean_absolute_error: 52.6251 - val_loss: 65.6251 - val_mean_absolute_error: 65.6251\n",
            "Epoch 66/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.6176 - mean_absolute_error: 52.6176 - val_loss: 65.7741 - val_mean_absolute_error: 65.7741\n",
            "Epoch 67/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.6102 - mean_absolute_error: 52.6102 - val_loss: 65.7918 - val_mean_absolute_error: 65.7918\n",
            "Epoch 68/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.6028 - mean_absolute_error: 52.6028 - val_loss: 65.8087 - val_mean_absolute_error: 65.8087\n",
            "Epoch 69/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.5950 - mean_absolute_error: 52.5950 - val_loss: 65.6429 - val_mean_absolute_error: 65.6429\n",
            "Epoch 70/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.5871 - mean_absolute_error: 52.5871 - val_loss: 65.7098 - val_mean_absolute_error: 65.7098\n",
            "Epoch 71/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.5796 - mean_absolute_error: 52.5796 - val_loss: 66.0150 - val_mean_absolute_error: 66.0150\n",
            "Epoch 72/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.5721 - mean_absolute_error: 52.5721 - val_loss: 66.0508 - val_mean_absolute_error: 66.0508\n",
            "Epoch 73/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.5645 - mean_absolute_error: 52.5645 - val_loss: 65.9333 - val_mean_absolute_error: 65.9333\n",
            "Epoch 74/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.5570 - mean_absolute_error: 52.5570 - val_loss: 65.6196 - val_mean_absolute_error: 65.6196\n",
            "Epoch 75/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.5498 - mean_absolute_error: 52.5498 - val_loss: 65.8175 - val_mean_absolute_error: 65.8175\n",
            "Epoch 76/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.5423 - mean_absolute_error: 52.5423 - val_loss: 65.8437 - val_mean_absolute_error: 65.8437\n",
            "Epoch 77/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.5351 - mean_absolute_error: 52.5351 - val_loss: 65.8853 - val_mean_absolute_error: 65.8853\n",
            "Epoch 78/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.5279 - mean_absolute_error: 52.5279 - val_loss: 65.7838 - val_mean_absolute_error: 65.7838\n",
            "Epoch 79/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.5207 - mean_absolute_error: 52.5207 - val_loss: 65.9254 - val_mean_absolute_error: 65.9254\n",
            "Epoch 80/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.5132 - mean_absolute_error: 52.5132 - val_loss: 66.0250 - val_mean_absolute_error: 66.0250\n",
            "Epoch 81/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.5068 - mean_absolute_error: 52.5068 - val_loss: 65.6437 - val_mean_absolute_error: 65.6437\n",
            "Epoch 82/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.4993 - mean_absolute_error: 52.4993 - val_loss: 65.9614 - val_mean_absolute_error: 65.9614\n",
            "Epoch 83/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.4924 - mean_absolute_error: 52.4924 - val_loss: 65.8967 - val_mean_absolute_error: 65.8967\n",
            "Epoch 84/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.4859 - mean_absolute_error: 52.4859 - val_loss: 65.9094 - val_mean_absolute_error: 65.9094\n",
            "Epoch 85/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.4793 - mean_absolute_error: 52.4793 - val_loss: 66.0029 - val_mean_absolute_error: 66.0029\n",
            "Epoch 86/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.4722 - mean_absolute_error: 52.4722 - val_loss: 65.9281 - val_mean_absolute_error: 65.9281\n",
            "Epoch 87/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.4658 - mean_absolute_error: 52.4658 - val_loss: 66.0173 - val_mean_absolute_error: 66.0173\n",
            "Epoch 88/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.4592 - mean_absolute_error: 52.4592 - val_loss: 65.8450 - val_mean_absolute_error: 65.8450\n",
            "Epoch 89/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.4528 - mean_absolute_error: 52.4528 - val_loss: 65.8563 - val_mean_absolute_error: 65.8563\n",
            "Epoch 90/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.4465 - mean_absolute_error: 52.4465 - val_loss: 65.8717 - val_mean_absolute_error: 65.8717\n",
            "Epoch 91/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.4401 - mean_absolute_error: 52.4401 - val_loss: 66.0658 - val_mean_absolute_error: 66.0658\n",
            "Epoch 92/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.4335 - mean_absolute_error: 52.4335 - val_loss: 65.8896 - val_mean_absolute_error: 65.8896\n",
            "Epoch 93/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.4268 - mean_absolute_error: 52.4268 - val_loss: 65.9776 - val_mean_absolute_error: 65.9776\n",
            "Epoch 94/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.4206 - mean_absolute_error: 52.4206 - val_loss: 65.9544 - val_mean_absolute_error: 65.9544\n",
            "Epoch 95/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.4143 - mean_absolute_error: 52.4143 - val_loss: 65.8694 - val_mean_absolute_error: 65.8694\n",
            "Epoch 96/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.4079 - mean_absolute_error: 52.4079 - val_loss: 65.9044 - val_mean_absolute_error: 65.9044\n",
            "Epoch 97/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.4018 - mean_absolute_error: 52.4018 - val_loss: 66.0950 - val_mean_absolute_error: 66.0950\n",
            "Epoch 98/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.3954 - mean_absolute_error: 52.3954 - val_loss: 66.0405 - val_mean_absolute_error: 66.0405\n",
            "Epoch 99/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.3890 - mean_absolute_error: 52.3890 - val_loss: 66.0210 - val_mean_absolute_error: 66.0210\n",
            "Epoch 100/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.3830 - mean_absolute_error: 52.3830 - val_loss: 65.8497 - val_mean_absolute_error: 65.8497\n",
            "Epoch 101/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.3768 - mean_absolute_error: 52.3768 - val_loss: 65.7511 - val_mean_absolute_error: 65.7511\n",
            "Epoch 102/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.3708 - mean_absolute_error: 52.3708 - val_loss: 65.9755 - val_mean_absolute_error: 65.9755\n",
            "Epoch 103/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.3646 - mean_absolute_error: 52.3646 - val_loss: 65.9351 - val_mean_absolute_error: 65.9351\n",
            "Epoch 104/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.3586 - mean_absolute_error: 52.3586 - val_loss: 66.0187 - val_mean_absolute_error: 66.0187\n",
            "Epoch 105/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.3528 - mean_absolute_error: 52.3528 - val_loss: 66.0654 - val_mean_absolute_error: 66.0654\n",
            "Epoch 106/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.3467 - mean_absolute_error: 52.3467 - val_loss: 65.9525 - val_mean_absolute_error: 65.9525\n",
            "Epoch 107/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.3405 - mean_absolute_error: 52.3405 - val_loss: 65.9648 - val_mean_absolute_error: 65.9648\n",
            "Epoch 108/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.3346 - mean_absolute_error: 52.3346 - val_loss: 66.0589 - val_mean_absolute_error: 66.0589\n",
            "Epoch 109/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.3286 - mean_absolute_error: 52.3286 - val_loss: 66.2329 - val_mean_absolute_error: 66.2329\n",
            "Epoch 110/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.3231 - mean_absolute_error: 52.3231 - val_loss: 66.1203 - val_mean_absolute_error: 66.1203\n",
            "Epoch 111/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.3172 - mean_absolute_error: 52.3172 - val_loss: 66.1229 - val_mean_absolute_error: 66.1229\n",
            "Epoch 112/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.3116 - mean_absolute_error: 52.3116 - val_loss: 66.0066 - val_mean_absolute_error: 66.0066\n",
            "Epoch 113/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.3061 - mean_absolute_error: 52.3061 - val_loss: 65.8151 - val_mean_absolute_error: 65.8151\n",
            "Epoch 114/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.3005 - mean_absolute_error: 52.3005 - val_loss: 66.1293 - val_mean_absolute_error: 66.1293\n",
            "Epoch 115/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.2949 - mean_absolute_error: 52.2949 - val_loss: 66.1920 - val_mean_absolute_error: 66.1920\n",
            "Epoch 116/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.2893 - mean_absolute_error: 52.2893 - val_loss: 65.9156 - val_mean_absolute_error: 65.9156\n",
            "Epoch 117/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.2841 - mean_absolute_error: 52.2841 - val_loss: 66.0369 - val_mean_absolute_error: 66.0369\n",
            "Epoch 118/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.2788 - mean_absolute_error: 52.2788 - val_loss: 66.1719 - val_mean_absolute_error: 66.1719\n",
            "Epoch 119/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.2734 - mean_absolute_error: 52.2734 - val_loss: 66.1055 - val_mean_absolute_error: 66.1055\n",
            "Epoch 120/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.2682 - mean_absolute_error: 52.2682 - val_loss: 66.0276 - val_mean_absolute_error: 66.0276\n",
            "Epoch 121/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.2628 - mean_absolute_error: 52.2628 - val_loss: 65.9232 - val_mean_absolute_error: 65.9232\n",
            "Epoch 122/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.2575 - mean_absolute_error: 52.2575 - val_loss: 65.9124 - val_mean_absolute_error: 65.9124\n",
            "Epoch 123/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.2529 - mean_absolute_error: 52.2529 - val_loss: 66.1689 - val_mean_absolute_error: 66.1689\n",
            "Epoch 124/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.2478 - mean_absolute_error: 52.2478 - val_loss: 65.9032 - val_mean_absolute_error: 65.9032\n",
            "Epoch 125/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.2425 - mean_absolute_error: 52.2425 - val_loss: 65.9036 - val_mean_absolute_error: 65.9036\n",
            "Epoch 126/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.2377 - mean_absolute_error: 52.2377 - val_loss: 66.0681 - val_mean_absolute_error: 66.0681\n",
            "Epoch 127/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.2326 - mean_absolute_error: 52.2326 - val_loss: 66.0123 - val_mean_absolute_error: 66.0123\n",
            "Epoch 128/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.2279 - mean_absolute_error: 52.2279 - val_loss: 66.1145 - val_mean_absolute_error: 66.1145\n",
            "Epoch 129/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.2227 - mean_absolute_error: 52.2227 - val_loss: 65.9970 - val_mean_absolute_error: 65.9970\n",
            "Epoch 130/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.2176 - mean_absolute_error: 52.2176 - val_loss: 66.0434 - val_mean_absolute_error: 66.0434\n",
            "Epoch 131/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.2126 - mean_absolute_error: 52.2126 - val_loss: 65.9033 - val_mean_absolute_error: 65.9033\n",
            "Epoch 132/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.2074 - mean_absolute_error: 52.2074 - val_loss: 66.0753 - val_mean_absolute_error: 66.0753\n",
            "Epoch 133/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.2029 - mean_absolute_error: 52.2029 - val_loss: 66.1813 - val_mean_absolute_error: 66.1813\n",
            "Epoch 134/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.1975 - mean_absolute_error: 52.1975 - val_loss: 65.9081 - val_mean_absolute_error: 65.9081\n",
            "Epoch 135/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.1925 - mean_absolute_error: 52.1925 - val_loss: 65.8817 - val_mean_absolute_error: 65.8817\n",
            "Epoch 136/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.1876 - mean_absolute_error: 52.1876 - val_loss: 66.1191 - val_mean_absolute_error: 66.1191\n",
            "Epoch 137/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.1826 - mean_absolute_error: 52.1826 - val_loss: 65.7717 - val_mean_absolute_error: 65.7717\n",
            "Epoch 138/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.1779 - mean_absolute_error: 52.1779 - val_loss: 65.9059 - val_mean_absolute_error: 65.9059\n",
            "Epoch 139/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.1730 - mean_absolute_error: 52.1730 - val_loss: 65.8631 - val_mean_absolute_error: 65.8631\n",
            "Epoch 140/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.1675 - mean_absolute_error: 52.1675 - val_loss: 65.9207 - val_mean_absolute_error: 65.9207\n",
            "Epoch 141/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.1622 - mean_absolute_error: 52.1622 - val_loss: 65.8784 - val_mean_absolute_error: 65.8784\n",
            "Epoch 142/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.1576 - mean_absolute_error: 52.1576 - val_loss: 65.8020 - val_mean_absolute_error: 65.8020\n",
            "Epoch 143/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.1523 - mean_absolute_error: 52.1523 - val_loss: 65.8034 - val_mean_absolute_error: 65.8034\n",
            "Epoch 144/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.1475 - mean_absolute_error: 52.1475 - val_loss: 65.7311 - val_mean_absolute_error: 65.7311\n",
            "Epoch 145/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.1417 - mean_absolute_error: 52.1417 - val_loss: 66.0602 - val_mean_absolute_error: 66.0602\n",
            "Epoch 146/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.1364 - mean_absolute_error: 52.1364 - val_loss: 65.8478 - val_mean_absolute_error: 65.8478\n",
            "Epoch 147/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.1310 - mean_absolute_error: 52.1310 - val_loss: 65.7326 - val_mean_absolute_error: 65.7326\n",
            "Epoch 148/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.1255 - mean_absolute_error: 52.1255 - val_loss: 65.8863 - val_mean_absolute_error: 65.8863\n",
            "Epoch 149/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.1197 - mean_absolute_error: 52.1197 - val_loss: 65.8610 - val_mean_absolute_error: 65.8610\n",
            "Epoch 150/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.1137 - mean_absolute_error: 52.1137 - val_loss: 65.9374 - val_mean_absolute_error: 65.9374\n",
            "Epoch 151/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.1079 - mean_absolute_error: 52.1079 - val_loss: 66.0943 - val_mean_absolute_error: 66.0943\n",
            "Epoch 152/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.1018 - mean_absolute_error: 52.1018 - val_loss: 66.0986 - val_mean_absolute_error: 66.0986\n",
            "Epoch 153/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.0965 - mean_absolute_error: 52.0965 - val_loss: 66.0900 - val_mean_absolute_error: 66.0900\n",
            "Epoch 154/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.0903 - mean_absolute_error: 52.0903 - val_loss: 65.7783 - val_mean_absolute_error: 65.7783\n",
            "Epoch 155/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.0843 - mean_absolute_error: 52.0843 - val_loss: 66.1813 - val_mean_absolute_error: 66.1813\n",
            "Epoch 156/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.0784 - mean_absolute_error: 52.0784 - val_loss: 65.8136 - val_mean_absolute_error: 65.8136\n",
            "Epoch 157/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.0723 - mean_absolute_error: 52.0723 - val_loss: 65.7547 - val_mean_absolute_error: 65.7547\n",
            "Epoch 158/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.0666 - mean_absolute_error: 52.0666 - val_loss: 65.8896 - val_mean_absolute_error: 65.8896\n",
            "Epoch 159/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.0602 - mean_absolute_error: 52.0602 - val_loss: 65.8931 - val_mean_absolute_error: 65.8931\n",
            "Epoch 160/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.0542 - mean_absolute_error: 52.0542 - val_loss: 65.7867 - val_mean_absolute_error: 65.7867\n",
            "Epoch 161/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.0482 - mean_absolute_error: 52.0482 - val_loss: 65.9453 - val_mean_absolute_error: 65.9453\n",
            "Epoch 162/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.0418 - mean_absolute_error: 52.0418 - val_loss: 65.9622 - val_mean_absolute_error: 65.9622\n",
            "Epoch 163/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.0356 - mean_absolute_error: 52.0356 - val_loss: 65.8944 - val_mean_absolute_error: 65.8944\n",
            "Epoch 164/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.0298 - mean_absolute_error: 52.0298 - val_loss: 65.9949 - val_mean_absolute_error: 65.9949\n",
            "Epoch 165/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.0234 - mean_absolute_error: 52.0234 - val_loss: 65.7962 - val_mean_absolute_error: 65.7962\n",
            "Epoch 166/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.0177 - mean_absolute_error: 52.0177 - val_loss: 65.9611 - val_mean_absolute_error: 65.9611\n",
            "Epoch 167/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.0116 - mean_absolute_error: 52.0116 - val_loss: 65.5849 - val_mean_absolute_error: 65.5849\n",
            "Epoch 168/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 52.0058 - mean_absolute_error: 52.0058 - val_loss: 65.9069 - val_mean_absolute_error: 65.9069\n",
            "Epoch 169/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.9997 - mean_absolute_error: 51.9997 - val_loss: 66.0616 - val_mean_absolute_error: 66.0616\n",
            "Epoch 170/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.9940 - mean_absolute_error: 51.9940 - val_loss: 65.8544 - val_mean_absolute_error: 65.8544\n",
            "Epoch 171/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.9884 - mean_absolute_error: 51.9884 - val_loss: 66.0241 - val_mean_absolute_error: 66.0241\n",
            "Epoch 172/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.9829 - mean_absolute_error: 51.9829 - val_loss: 65.8251 - val_mean_absolute_error: 65.8251\n",
            "Epoch 173/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.9773 - mean_absolute_error: 51.9773 - val_loss: 65.7318 - val_mean_absolute_error: 65.7318\n",
            "Epoch 174/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.9719 - mean_absolute_error: 51.9719 - val_loss: 65.9914 - val_mean_absolute_error: 65.9914\n",
            "Epoch 175/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.9661 - mean_absolute_error: 51.9661 - val_loss: 65.9331 - val_mean_absolute_error: 65.9331\n",
            "Epoch 176/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.9606 - mean_absolute_error: 51.9606 - val_loss: 65.9752 - val_mean_absolute_error: 65.9752\n",
            "Epoch 177/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.9546 - mean_absolute_error: 51.9546 - val_loss: 65.8610 - val_mean_absolute_error: 65.8610\n",
            "Epoch 178/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.9496 - mean_absolute_error: 51.9496 - val_loss: 65.8824 - val_mean_absolute_error: 65.8824\n",
            "Epoch 179/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.9442 - mean_absolute_error: 51.9442 - val_loss: 65.8451 - val_mean_absolute_error: 65.8451\n",
            "Epoch 180/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.9391 - mean_absolute_error: 51.9391 - val_loss: 66.0492 - val_mean_absolute_error: 66.0492\n",
            "Epoch 181/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.9335 - mean_absolute_error: 51.9335 - val_loss: 65.9982 - val_mean_absolute_error: 65.9982\n",
            "Epoch 182/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.9286 - mean_absolute_error: 51.9286 - val_loss: 65.8810 - val_mean_absolute_error: 65.8810\n",
            "Epoch 183/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.9233 - mean_absolute_error: 51.9233 - val_loss: 66.0134 - val_mean_absolute_error: 66.0134\n",
            "Epoch 184/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.9178 - mean_absolute_error: 51.9178 - val_loss: 65.8677 - val_mean_absolute_error: 65.8677\n",
            "Epoch 185/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.9129 - mean_absolute_error: 51.9129 - val_loss: 65.9447 - val_mean_absolute_error: 65.9447\n",
            "Epoch 186/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.9082 - mean_absolute_error: 51.9082 - val_loss: 65.9491 - val_mean_absolute_error: 65.9491\n",
            "Epoch 187/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.9028 - mean_absolute_error: 51.9028 - val_loss: 65.8469 - val_mean_absolute_error: 65.8469\n",
            "Epoch 188/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.8980 - mean_absolute_error: 51.8980 - val_loss: 65.8309 - val_mean_absolute_error: 65.8309\n",
            "Epoch 189/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.8933 - mean_absolute_error: 51.8933 - val_loss: 66.0954 - val_mean_absolute_error: 66.0954\n",
            "Epoch 190/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.8883 - mean_absolute_error: 51.8883 - val_loss: 65.9175 - val_mean_absolute_error: 65.9175\n",
            "Epoch 191/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.8832 - mean_absolute_error: 51.8832 - val_loss: 65.7483 - val_mean_absolute_error: 65.7483\n",
            "Epoch 192/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.8785 - mean_absolute_error: 51.8785 - val_loss: 65.9376 - val_mean_absolute_error: 65.9376\n",
            "Epoch 193/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.8733 - mean_absolute_error: 51.8733 - val_loss: 66.0680 - val_mean_absolute_error: 66.0680\n",
            "Epoch 194/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.8684 - mean_absolute_error: 51.8684 - val_loss: 66.1825 - val_mean_absolute_error: 66.1825\n",
            "Epoch 195/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.8639 - mean_absolute_error: 51.8639 - val_loss: 66.2143 - val_mean_absolute_error: 66.2143\n",
            "Epoch 196/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.8589 - mean_absolute_error: 51.8589 - val_loss: 65.7368 - val_mean_absolute_error: 65.7368\n",
            "Epoch 197/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.8540 - mean_absolute_error: 51.8540 - val_loss: 65.7771 - val_mean_absolute_error: 65.7771\n",
            "Epoch 198/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.8491 - mean_absolute_error: 51.8491 - val_loss: 66.0636 - val_mean_absolute_error: 66.0636\n",
            "Epoch 199/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.8444 - mean_absolute_error: 51.8444 - val_loss: 66.0450 - val_mean_absolute_error: 66.0450\n",
            "Epoch 200/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.8389 - mean_absolute_error: 51.8389 - val_loss: 65.9636 - val_mean_absolute_error: 65.9636\n",
            "Epoch 201/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.8341 - mean_absolute_error: 51.8341 - val_loss: 65.8683 - val_mean_absolute_error: 65.8683\n",
            "Epoch 202/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.8291 - mean_absolute_error: 51.8291 - val_loss: 65.6056 - val_mean_absolute_error: 65.6056\n",
            "Epoch 203/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.8242 - mean_absolute_error: 51.8242 - val_loss: 65.9162 - val_mean_absolute_error: 65.9162\n",
            "Epoch 204/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.8194 - mean_absolute_error: 51.8194 - val_loss: 66.1055 - val_mean_absolute_error: 66.1055\n",
            "Epoch 205/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.8144 - mean_absolute_error: 51.8144 - val_loss: 65.7406 - val_mean_absolute_error: 65.7406\n",
            "Epoch 206/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.8098 - mean_absolute_error: 51.8098 - val_loss: 65.7126 - val_mean_absolute_error: 65.7126\n",
            "Epoch 207/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.8047 - mean_absolute_error: 51.8047 - val_loss: 65.6960 - val_mean_absolute_error: 65.6960\n",
            "Epoch 208/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.7998 - mean_absolute_error: 51.7998 - val_loss: 66.0417 - val_mean_absolute_error: 66.0417\n",
            "Epoch 209/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.7951 - mean_absolute_error: 51.7951 - val_loss: 65.7492 - val_mean_absolute_error: 65.7492\n",
            "Epoch 210/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.7902 - mean_absolute_error: 51.7902 - val_loss: 65.5969 - val_mean_absolute_error: 65.5969\n",
            "Epoch 211/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.7852 - mean_absolute_error: 51.7852 - val_loss: 65.8909 - val_mean_absolute_error: 65.8909\n",
            "Epoch 212/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.7801 - mean_absolute_error: 51.7801 - val_loss: 65.8164 - val_mean_absolute_error: 65.8164\n",
            "Epoch 213/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.7754 - mean_absolute_error: 51.7754 - val_loss: 65.7071 - val_mean_absolute_error: 65.7071\n",
            "Epoch 214/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.7706 - mean_absolute_error: 51.7706 - val_loss: 65.6444 - val_mean_absolute_error: 65.6444\n",
            "Epoch 215/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.7658 - mean_absolute_error: 51.7658 - val_loss: 65.6777 - val_mean_absolute_error: 65.6777\n",
            "Epoch 216/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.7608 - mean_absolute_error: 51.7608 - val_loss: 66.0499 - val_mean_absolute_error: 66.0499\n",
            "Epoch 217/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.7558 - mean_absolute_error: 51.7558 - val_loss: 65.7891 - val_mean_absolute_error: 65.7891\n",
            "Epoch 218/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.7509 - mean_absolute_error: 51.7509 - val_loss: 65.8349 - val_mean_absolute_error: 65.8349\n",
            "Epoch 219/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.7460 - mean_absolute_error: 51.7460 - val_loss: 65.7574 - val_mean_absolute_error: 65.7574\n",
            "Epoch 220/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.7410 - mean_absolute_error: 51.7410 - val_loss: 65.7585 - val_mean_absolute_error: 65.7585\n",
            "Epoch 221/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.7360 - mean_absolute_error: 51.7360 - val_loss: 65.7351 - val_mean_absolute_error: 65.7351\n",
            "Epoch 222/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.7312 - mean_absolute_error: 51.7312 - val_loss: 65.9508 - val_mean_absolute_error: 65.9508\n",
            "Epoch 223/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.7262 - mean_absolute_error: 51.7262 - val_loss: 65.7653 - val_mean_absolute_error: 65.7653\n",
            "Epoch 224/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.7209 - mean_absolute_error: 51.7209 - val_loss: 65.6317 - val_mean_absolute_error: 65.6317\n",
            "Epoch 225/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.7155 - mean_absolute_error: 51.7155 - val_loss: 65.7368 - val_mean_absolute_error: 65.7368\n",
            "Epoch 226/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.7107 - mean_absolute_error: 51.7107 - val_loss: 65.6909 - val_mean_absolute_error: 65.6909\n",
            "Epoch 227/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.7055 - mean_absolute_error: 51.7055 - val_loss: 65.7050 - val_mean_absolute_error: 65.7050\n",
            "Epoch 228/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.7003 - mean_absolute_error: 51.7003 - val_loss: 65.7697 - val_mean_absolute_error: 65.7697\n",
            "Epoch 229/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.6951 - mean_absolute_error: 51.6951 - val_loss: 65.8874 - val_mean_absolute_error: 65.8874\n",
            "Epoch 230/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.6901 - mean_absolute_error: 51.6901 - val_loss: 65.7043 - val_mean_absolute_error: 65.7043\n",
            "Epoch 231/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.6850 - mean_absolute_error: 51.6850 - val_loss: 65.5465 - val_mean_absolute_error: 65.5465\n",
            "Epoch 232/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.6796 - mean_absolute_error: 51.6796 - val_loss: 65.3439 - val_mean_absolute_error: 65.3439\n",
            "Epoch 233/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.6747 - mean_absolute_error: 51.6747 - val_loss: 65.4829 - val_mean_absolute_error: 65.4829\n",
            "Epoch 234/1000\n",
            "769500/769500 [==============================] - 1s 2us/step - loss: 51.6690 - mean_absolute_error: 51.6690 - val_loss: 65.8371 - val_mean_absolute_error: 65.8371\n",
            "Epoch 235/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.6635 - mean_absolute_error: 51.6635 - val_loss: 65.7325 - val_mean_absolute_error: 65.7325\n",
            "Epoch 236/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.6582 - mean_absolute_error: 51.6582 - val_loss: 65.5505 - val_mean_absolute_error: 65.5505\n",
            "Epoch 237/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.6528 - mean_absolute_error: 51.6528 - val_loss: 65.7152 - val_mean_absolute_error: 65.7152\n",
            "Epoch 238/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.6471 - mean_absolute_error: 51.6471 - val_loss: 65.6812 - val_mean_absolute_error: 65.6812\n",
            "Epoch 239/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.6414 - mean_absolute_error: 51.6414 - val_loss: 65.5741 - val_mean_absolute_error: 65.5741\n",
            "Epoch 240/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.6356 - mean_absolute_error: 51.6356 - val_loss: 65.6469 - val_mean_absolute_error: 65.6469\n",
            "Epoch 241/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.6307 - mean_absolute_error: 51.6307 - val_loss: 65.6711 - val_mean_absolute_error: 65.6711\n",
            "Epoch 242/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.6250 - mean_absolute_error: 51.6250 - val_loss: 65.8707 - val_mean_absolute_error: 65.8707\n",
            "Epoch 243/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.6191 - mean_absolute_error: 51.6191 - val_loss: 65.7641 - val_mean_absolute_error: 65.7641\n",
            "Epoch 244/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.6132 - mean_absolute_error: 51.6132 - val_loss: 65.4348 - val_mean_absolute_error: 65.4348\n",
            "Epoch 245/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.6071 - mean_absolute_error: 51.6071 - val_loss: 65.8443 - val_mean_absolute_error: 65.8443\n",
            "Epoch 246/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.6011 - mean_absolute_error: 51.6011 - val_loss: 65.7671 - val_mean_absolute_error: 65.7671\n",
            "Epoch 247/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.5956 - mean_absolute_error: 51.5956 - val_loss: 65.7387 - val_mean_absolute_error: 65.7387\n",
            "Epoch 248/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.5894 - mean_absolute_error: 51.5894 - val_loss: 65.6748 - val_mean_absolute_error: 65.6748\n",
            "Epoch 249/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.5837 - mean_absolute_error: 51.5837 - val_loss: 65.6269 - val_mean_absolute_error: 65.6269\n",
            "Epoch 250/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.5776 - mean_absolute_error: 51.5776 - val_loss: 65.6111 - val_mean_absolute_error: 65.6111\n",
            "Epoch 251/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.5717 - mean_absolute_error: 51.5717 - val_loss: 65.3620 - val_mean_absolute_error: 65.3620\n",
            "Epoch 252/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.5656 - mean_absolute_error: 51.5656 - val_loss: 65.4453 - val_mean_absolute_error: 65.4453\n",
            "Epoch 253/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.5599 - mean_absolute_error: 51.5599 - val_loss: 65.1940 - val_mean_absolute_error: 65.1940\n",
            "Epoch 254/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.5538 - mean_absolute_error: 51.5538 - val_loss: 65.4645 - val_mean_absolute_error: 65.4645\n",
            "Epoch 255/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.5473 - mean_absolute_error: 51.5473 - val_loss: 65.3877 - val_mean_absolute_error: 65.3877\n",
            "Epoch 256/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.5409 - mean_absolute_error: 51.5409 - val_loss: 65.4221 - val_mean_absolute_error: 65.4221\n",
            "Epoch 257/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.5347 - mean_absolute_error: 51.5347 - val_loss: 65.4618 - val_mean_absolute_error: 65.4618\n",
            "Epoch 258/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.5284 - mean_absolute_error: 51.5284 - val_loss: 65.2809 - val_mean_absolute_error: 65.2809\n",
            "Epoch 259/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.5223 - mean_absolute_error: 51.5223 - val_loss: 65.4935 - val_mean_absolute_error: 65.4935\n",
            "Epoch 260/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.5155 - mean_absolute_error: 51.5155 - val_loss: 65.1776 - val_mean_absolute_error: 65.1776\n",
            "Epoch 261/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.5089 - mean_absolute_error: 51.5089 - val_loss: 65.1494 - val_mean_absolute_error: 65.1494\n",
            "Epoch 262/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.5020 - mean_absolute_error: 51.5020 - val_loss: 65.2535 - val_mean_absolute_error: 65.2535\n",
            "Epoch 263/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.4956 - mean_absolute_error: 51.4956 - val_loss: 65.4264 - val_mean_absolute_error: 65.4264\n",
            "Epoch 264/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.4885 - mean_absolute_error: 51.4885 - val_loss: 65.3679 - val_mean_absolute_error: 65.3679\n",
            "Epoch 265/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.4815 - mean_absolute_error: 51.4815 - val_loss: 65.1074 - val_mean_absolute_error: 65.1074\n",
            "Epoch 266/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.4744 - mean_absolute_error: 51.4744 - val_loss: 65.5085 - val_mean_absolute_error: 65.5085\n",
            "Epoch 267/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.4672 - mean_absolute_error: 51.4672 - val_loss: 65.0963 - val_mean_absolute_error: 65.0963\n",
            "Epoch 268/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.4600 - mean_absolute_error: 51.4600 - val_loss: 65.0069 - val_mean_absolute_error: 65.0069\n",
            "Epoch 269/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.4530 - mean_absolute_error: 51.4530 - val_loss: 64.8158 - val_mean_absolute_error: 64.8158\n",
            "Epoch 270/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.4453 - mean_absolute_error: 51.4453 - val_loss: 64.8972 - val_mean_absolute_error: 64.8972\n",
            "Epoch 271/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.4380 - mean_absolute_error: 51.4380 - val_loss: 64.9110 - val_mean_absolute_error: 64.9110\n",
            "Epoch 272/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.4304 - mean_absolute_error: 51.4304 - val_loss: 64.8487 - val_mean_absolute_error: 64.8487\n",
            "Epoch 273/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.4229 - mean_absolute_error: 51.4229 - val_loss: 65.2245 - val_mean_absolute_error: 65.2245\n",
            "Epoch 274/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.4154 - mean_absolute_error: 51.4154 - val_loss: 65.2131 - val_mean_absolute_error: 65.2131\n",
            "Epoch 275/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.4083 - mean_absolute_error: 51.4083 - val_loss: 65.3308 - val_mean_absolute_error: 65.3308\n",
            "Epoch 276/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.4011 - mean_absolute_error: 51.4011 - val_loss: 65.1577 - val_mean_absolute_error: 65.1577\n",
            "Epoch 277/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.3937 - mean_absolute_error: 51.3937 - val_loss: 64.6882 - val_mean_absolute_error: 64.6882\n",
            "Epoch 278/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.3862 - mean_absolute_error: 51.3862 - val_loss: 64.8997 - val_mean_absolute_error: 64.8997\n",
            "Epoch 279/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.3784 - mean_absolute_error: 51.3784 - val_loss: 64.7196 - val_mean_absolute_error: 64.7196\n",
            "Epoch 280/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.3712 - mean_absolute_error: 51.3712 - val_loss: 64.7527 - val_mean_absolute_error: 64.7527\n",
            "Epoch 281/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.3638 - mean_absolute_error: 51.3638 - val_loss: 64.6178 - val_mean_absolute_error: 64.6178\n",
            "Epoch 282/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.3562 - mean_absolute_error: 51.3562 - val_loss: 64.7603 - val_mean_absolute_error: 64.7603\n",
            "Epoch 283/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.3494 - mean_absolute_error: 51.3494 - val_loss: 64.7306 - val_mean_absolute_error: 64.7306\n",
            "Epoch 284/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.3420 - mean_absolute_error: 51.3420 - val_loss: 64.6482 - val_mean_absolute_error: 64.6482\n",
            "Epoch 285/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.3348 - mean_absolute_error: 51.3348 - val_loss: 64.6025 - val_mean_absolute_error: 64.6025\n",
            "Epoch 286/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.3280 - mean_absolute_error: 51.3280 - val_loss: 64.4823 - val_mean_absolute_error: 64.4823\n",
            "Epoch 287/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.3209 - mean_absolute_error: 51.3209 - val_loss: 64.5351 - val_mean_absolute_error: 64.5351\n",
            "Epoch 288/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.3138 - mean_absolute_error: 51.3138 - val_loss: 64.6347 - val_mean_absolute_error: 64.6347\n",
            "Epoch 289/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.3065 - mean_absolute_error: 51.3065 - val_loss: 64.6150 - val_mean_absolute_error: 64.6150\n",
            "Epoch 290/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.2998 - mean_absolute_error: 51.2998 - val_loss: 64.3252 - val_mean_absolute_error: 64.3252\n",
            "Epoch 291/1000\n",
            "769500/769500 [==============================] - 1s 2us/step - loss: 51.2926 - mean_absolute_error: 51.2926 - val_loss: 64.8630 - val_mean_absolute_error: 64.8630\n",
            "Epoch 292/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.2863 - mean_absolute_error: 51.2863 - val_loss: 64.5818 - val_mean_absolute_error: 64.5818\n",
            "Epoch 293/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.2798 - mean_absolute_error: 51.2798 - val_loss: 64.4384 - val_mean_absolute_error: 64.4384\n",
            "Epoch 294/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.2733 - mean_absolute_error: 51.2733 - val_loss: 64.4322 - val_mean_absolute_error: 64.4322\n",
            "Epoch 295/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.2666 - mean_absolute_error: 51.2666 - val_loss: 64.6922 - val_mean_absolute_error: 64.6922\n",
            "Epoch 296/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.2600 - mean_absolute_error: 51.2600 - val_loss: 64.4856 - val_mean_absolute_error: 64.4856\n",
            "Epoch 297/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.2535 - mean_absolute_error: 51.2535 - val_loss: 64.7811 - val_mean_absolute_error: 64.7811\n",
            "Epoch 298/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.2469 - mean_absolute_error: 51.2469 - val_loss: 64.4144 - val_mean_absolute_error: 64.4144\n",
            "Epoch 299/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.2402 - mean_absolute_error: 51.2402 - val_loss: 64.5398 - val_mean_absolute_error: 64.5398\n",
            "Epoch 300/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.2333 - mean_absolute_error: 51.2333 - val_loss: 64.5132 - val_mean_absolute_error: 64.5132\n",
            "Epoch 301/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.2271 - mean_absolute_error: 51.2271 - val_loss: 64.1649 - val_mean_absolute_error: 64.1649\n",
            "Epoch 302/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.2204 - mean_absolute_error: 51.2204 - val_loss: 64.1624 - val_mean_absolute_error: 64.1624\n",
            "Epoch 303/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.2136 - mean_absolute_error: 51.2136 - val_loss: 64.4854 - val_mean_absolute_error: 64.4854\n",
            "Epoch 304/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.2077 - mean_absolute_error: 51.2077 - val_loss: 64.4454 - val_mean_absolute_error: 64.4454\n",
            "Epoch 305/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.2012 - mean_absolute_error: 51.2012 - val_loss: 64.5731 - val_mean_absolute_error: 64.5731\n",
            "Epoch 306/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.1952 - mean_absolute_error: 51.1952 - val_loss: 64.2773 - val_mean_absolute_error: 64.2773\n",
            "Epoch 307/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.1892 - mean_absolute_error: 51.1892 - val_loss: 64.2232 - val_mean_absolute_error: 64.2232\n",
            "Epoch 308/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.1832 - mean_absolute_error: 51.1832 - val_loss: 64.2610 - val_mean_absolute_error: 64.2610\n",
            "Epoch 309/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.1771 - mean_absolute_error: 51.1771 - val_loss: 64.3479 - val_mean_absolute_error: 64.3479\n",
            "Epoch 310/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.1713 - mean_absolute_error: 51.1713 - val_loss: 64.2878 - val_mean_absolute_error: 64.2878\n",
            "Epoch 311/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.1655 - mean_absolute_error: 51.1655 - val_loss: 64.3133 - val_mean_absolute_error: 64.3133\n",
            "Epoch 312/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.1600 - mean_absolute_error: 51.1600 - val_loss: 64.0735 - val_mean_absolute_error: 64.0735\n",
            "Epoch 313/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.1546 - mean_absolute_error: 51.1546 - val_loss: 64.1936 - val_mean_absolute_error: 64.1936\n",
            "Epoch 314/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.1495 - mean_absolute_error: 51.1495 - val_loss: 64.0535 - val_mean_absolute_error: 64.0535\n",
            "Epoch 315/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.1438 - mean_absolute_error: 51.1438 - val_loss: 64.4920 - val_mean_absolute_error: 64.4920\n",
            "Epoch 316/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.1388 - mean_absolute_error: 51.1388 - val_loss: 64.3492 - val_mean_absolute_error: 64.3492\n",
            "Epoch 317/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.1336 - mean_absolute_error: 51.1336 - val_loss: 64.3261 - val_mean_absolute_error: 64.3261\n",
            "Epoch 318/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.1287 - mean_absolute_error: 51.1287 - val_loss: 63.8783 - val_mean_absolute_error: 63.8783\n",
            "Epoch 319/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.1238 - mean_absolute_error: 51.1238 - val_loss: 64.1492 - val_mean_absolute_error: 64.1492\n",
            "Epoch 320/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.1185 - mean_absolute_error: 51.1185 - val_loss: 64.1494 - val_mean_absolute_error: 64.1494\n",
            "Epoch 321/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.1137 - mean_absolute_error: 51.1137 - val_loss: 64.1008 - val_mean_absolute_error: 64.1008\n",
            "Epoch 322/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.1089 - mean_absolute_error: 51.1089 - val_loss: 64.1730 - val_mean_absolute_error: 64.1730\n",
            "Epoch 323/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.1041 - mean_absolute_error: 51.1041 - val_loss: 64.1646 - val_mean_absolute_error: 64.1646\n",
            "Epoch 324/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.0994 - mean_absolute_error: 51.0994 - val_loss: 64.2921 - val_mean_absolute_error: 64.2921\n",
            "Epoch 325/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.0950 - mean_absolute_error: 51.0950 - val_loss: 64.1438 - val_mean_absolute_error: 64.1438\n",
            "Epoch 326/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.0904 - mean_absolute_error: 51.0904 - val_loss: 64.2101 - val_mean_absolute_error: 64.2101\n",
            "Epoch 327/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.0860 - mean_absolute_error: 51.0860 - val_loss: 64.1743 - val_mean_absolute_error: 64.1743\n",
            "Epoch 328/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.0816 - mean_absolute_error: 51.0816 - val_loss: 64.0190 - val_mean_absolute_error: 64.0190\n",
            "Epoch 329/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.0775 - mean_absolute_error: 51.0775 - val_loss: 64.0629 - val_mean_absolute_error: 64.0629\n",
            "Epoch 330/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.0733 - mean_absolute_error: 51.0733 - val_loss: 63.9488 - val_mean_absolute_error: 63.9488\n",
            "Epoch 331/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.0691 - mean_absolute_error: 51.0691 - val_loss: 64.1904 - val_mean_absolute_error: 64.1904\n",
            "Epoch 332/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.0651 - mean_absolute_error: 51.0651 - val_loss: 63.8656 - val_mean_absolute_error: 63.8656\n",
            "Epoch 333/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.0613 - mean_absolute_error: 51.0613 - val_loss: 63.9311 - val_mean_absolute_error: 63.9311\n",
            "Epoch 334/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.0573 - mean_absolute_error: 51.0573 - val_loss: 64.1234 - val_mean_absolute_error: 64.1234\n",
            "Epoch 335/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.0534 - mean_absolute_error: 51.0534 - val_loss: 64.4539 - val_mean_absolute_error: 64.4539\n",
            "Epoch 336/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.0496 - mean_absolute_error: 51.0496 - val_loss: 64.3963 - val_mean_absolute_error: 64.3963\n",
            "Epoch 337/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.0461 - mean_absolute_error: 51.0461 - val_loss: 64.2637 - val_mean_absolute_error: 64.2637\n",
            "Epoch 338/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.0426 - mean_absolute_error: 51.0426 - val_loss: 64.1069 - val_mean_absolute_error: 64.1069\n",
            "Epoch 339/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.0390 - mean_absolute_error: 51.0390 - val_loss: 64.0259 - val_mean_absolute_error: 64.0259\n",
            "Epoch 340/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.0357 - mean_absolute_error: 51.0357 - val_loss: 63.9168 - val_mean_absolute_error: 63.9168\n",
            "Epoch 341/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.0327 - mean_absolute_error: 51.0327 - val_loss: 64.1175 - val_mean_absolute_error: 64.1175\n",
            "Epoch 342/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.0292 - mean_absolute_error: 51.0292 - val_loss: 63.8774 - val_mean_absolute_error: 63.8774\n",
            "Epoch 343/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.0263 - mean_absolute_error: 51.0263 - val_loss: 63.6421 - val_mean_absolute_error: 63.6421\n",
            "Epoch 344/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.0234 - mean_absolute_error: 51.0234 - val_loss: 64.1944 - val_mean_absolute_error: 64.1944\n",
            "Epoch 345/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.0199 - mean_absolute_error: 51.0199 - val_loss: 64.0660 - val_mean_absolute_error: 64.0660\n",
            "Epoch 346/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.0170 - mean_absolute_error: 51.0170 - val_loss: 64.0026 - val_mean_absolute_error: 64.0026\n",
            "Epoch 347/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.0142 - mean_absolute_error: 51.0142 - val_loss: 63.7644 - val_mean_absolute_error: 63.7644\n",
            "Epoch 348/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.0117 - mean_absolute_error: 51.0117 - val_loss: 64.2163 - val_mean_absolute_error: 64.2163\n",
            "Epoch 349/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.0086 - mean_absolute_error: 51.0086 - val_loss: 64.1493 - val_mean_absolute_error: 64.1493\n",
            "Epoch 350/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.0062 - mean_absolute_error: 51.0062 - val_loss: 63.8581 - val_mean_absolute_error: 63.8581\n",
            "Epoch 351/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.0037 - mean_absolute_error: 51.0037 - val_loss: 64.1809 - val_mean_absolute_error: 64.1809\n",
            "Epoch 352/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 51.0012 - mean_absolute_error: 51.0012 - val_loss: 64.0023 - val_mean_absolute_error: 64.0023\n",
            "Epoch 353/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.9985 - mean_absolute_error: 50.9985 - val_loss: 64.2435 - val_mean_absolute_error: 64.2435\n",
            "Epoch 354/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.9961 - mean_absolute_error: 50.9961 - val_loss: 63.8558 - val_mean_absolute_error: 63.8558\n",
            "Epoch 355/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.9938 - mean_absolute_error: 50.9938 - val_loss: 63.9429 - val_mean_absolute_error: 63.9429\n",
            "Epoch 356/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.9915 - mean_absolute_error: 50.9915 - val_loss: 63.8101 - val_mean_absolute_error: 63.8101\n",
            "Epoch 357/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.9890 - mean_absolute_error: 50.9890 - val_loss: 64.0105 - val_mean_absolute_error: 64.0105\n",
            "Epoch 358/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.9871 - mean_absolute_error: 50.9871 - val_loss: 64.0805 - val_mean_absolute_error: 64.0805\n",
            "Epoch 359/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.9843 - mean_absolute_error: 50.9843 - val_loss: 63.7568 - val_mean_absolute_error: 63.7568\n",
            "Epoch 360/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.9821 - mean_absolute_error: 50.9821 - val_loss: 64.0287 - val_mean_absolute_error: 64.0287\n",
            "Epoch 361/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.9801 - mean_absolute_error: 50.9801 - val_loss: 63.7431 - val_mean_absolute_error: 63.7431\n",
            "Epoch 362/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.9781 - mean_absolute_error: 50.9781 - val_loss: 63.6082 - val_mean_absolute_error: 63.6082\n",
            "Epoch 363/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.9767 - mean_absolute_error: 50.9767 - val_loss: 64.0435 - val_mean_absolute_error: 64.0435\n",
            "Epoch 364/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.9745 - mean_absolute_error: 50.9745 - val_loss: 63.9774 - val_mean_absolute_error: 63.9774\n",
            "Epoch 365/1000\n",
            "769500/769500 [==============================] - 1s 2us/step - loss: 50.9728 - mean_absolute_error: 50.9728 - val_loss: 64.1045 - val_mean_absolute_error: 64.1045\n",
            "Epoch 366/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.9709 - mean_absolute_error: 50.9709 - val_loss: 64.0136 - val_mean_absolute_error: 64.0136\n",
            "Epoch 367/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.9691 - mean_absolute_error: 50.9691 - val_loss: 64.3294 - val_mean_absolute_error: 64.3294\n",
            "Epoch 368/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.9671 - mean_absolute_error: 50.9671 - val_loss: 63.6234 - val_mean_absolute_error: 63.6234\n",
            "Epoch 369/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.9656 - mean_absolute_error: 50.9656 - val_loss: 64.3905 - val_mean_absolute_error: 64.3905\n",
            "Epoch 370/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.9646 - mean_absolute_error: 50.9646 - val_loss: 64.0790 - val_mean_absolute_error: 64.0790\n",
            "Epoch 371/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.9622 - mean_absolute_error: 50.9622 - val_loss: 63.9721 - val_mean_absolute_error: 63.9721\n",
            "Epoch 372/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.9602 - mean_absolute_error: 50.9602 - val_loss: 64.0838 - val_mean_absolute_error: 64.0838\n",
            "Epoch 373/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.9593 - mean_absolute_error: 50.9593 - val_loss: 64.0302 - val_mean_absolute_error: 64.0302\n",
            "Epoch 374/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.9574 - mean_absolute_error: 50.9574 - val_loss: 64.0288 - val_mean_absolute_error: 64.0288\n",
            "Epoch 375/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.9555 - mean_absolute_error: 50.9555 - val_loss: 64.0528 - val_mean_absolute_error: 64.0528\n",
            "Epoch 376/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.9544 - mean_absolute_error: 50.9544 - val_loss: 64.2792 - val_mean_absolute_error: 64.2792\n",
            "Epoch 377/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.9533 - mean_absolute_error: 50.9533 - val_loss: 64.2917 - val_mean_absolute_error: 64.2917\n",
            "Epoch 378/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.9519 - mean_absolute_error: 50.9519 - val_loss: 63.9741 - val_mean_absolute_error: 63.9741\n",
            "Epoch 379/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.9502 - mean_absolute_error: 50.9502 - val_loss: 64.0135 - val_mean_absolute_error: 64.0135\n",
            "Epoch 380/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.9490 - mean_absolute_error: 50.9490 - val_loss: 63.7628 - val_mean_absolute_error: 63.7628\n",
            "Epoch 381/1000\n",
            "769500/769500 [==============================] - 1s 2us/step - loss: 50.9473 - mean_absolute_error: 50.9473 - val_loss: 64.1923 - val_mean_absolute_error: 64.1923\n",
            "Epoch 382/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.9459 - mean_absolute_error: 50.9459 - val_loss: 64.3654 - val_mean_absolute_error: 64.3654\n",
            "Epoch 383/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.9443 - mean_absolute_error: 50.9443 - val_loss: 63.8785 - val_mean_absolute_error: 63.8785\n",
            "Epoch 384/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.9436 - mean_absolute_error: 50.9436 - val_loss: 64.1242 - val_mean_absolute_error: 64.1242\n",
            "Epoch 385/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.9423 - mean_absolute_error: 50.9423 - val_loss: 63.9416 - val_mean_absolute_error: 63.9416\n",
            "Epoch 386/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.9409 - mean_absolute_error: 50.9409 - val_loss: 64.0473 - val_mean_absolute_error: 64.0473\n",
            "Epoch 387/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.9396 - mean_absolute_error: 50.9396 - val_loss: 63.7202 - val_mean_absolute_error: 63.7202\n",
            "Epoch 388/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.9383 - mean_absolute_error: 50.9383 - val_loss: 63.8429 - val_mean_absolute_error: 63.8429\n",
            "Epoch 389/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.9371 - mean_absolute_error: 50.9371 - val_loss: 64.2046 - val_mean_absolute_error: 64.2046\n",
            "Epoch 390/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.9360 - mean_absolute_error: 50.9360 - val_loss: 63.7908 - val_mean_absolute_error: 63.7908\n",
            "Epoch 391/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.9346 - mean_absolute_error: 50.9346 - val_loss: 63.6304 - val_mean_absolute_error: 63.6304\n",
            "Epoch 392/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.9336 - mean_absolute_error: 50.9336 - val_loss: 64.1918 - val_mean_absolute_error: 64.1918\n",
            "Epoch 393/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.9320 - mean_absolute_error: 50.9320 - val_loss: 63.8591 - val_mean_absolute_error: 63.8591\n",
            "Epoch 394/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.9314 - mean_absolute_error: 50.9314 - val_loss: 64.1497 - val_mean_absolute_error: 64.1497\n",
            "Epoch 395/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.9295 - mean_absolute_error: 50.9295 - val_loss: 63.7928 - val_mean_absolute_error: 63.7928\n",
            "Epoch 396/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.9289 - mean_absolute_error: 50.9289 - val_loss: 64.1034 - val_mean_absolute_error: 64.1034\n",
            "Epoch 397/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.9273 - mean_absolute_error: 50.9273 - val_loss: 63.8837 - val_mean_absolute_error: 63.8837\n",
            "Epoch 398/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.9263 - mean_absolute_error: 50.9263 - val_loss: 64.1765 - val_mean_absolute_error: 64.1765\n",
            "Epoch 399/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.9249 - mean_absolute_error: 50.9249 - val_loss: 64.2650 - val_mean_absolute_error: 64.2650\n",
            "Epoch 400/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.9235 - mean_absolute_error: 50.9235 - val_loss: 63.7974 - val_mean_absolute_error: 63.7974\n",
            "Epoch 401/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.9225 - mean_absolute_error: 50.9225 - val_loss: 63.9492 - val_mean_absolute_error: 63.9492\n",
            "Epoch 402/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.9216 - mean_absolute_error: 50.9216 - val_loss: 63.7844 - val_mean_absolute_error: 63.7844\n",
            "Epoch 403/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.9201 - mean_absolute_error: 50.9201 - val_loss: 64.1887 - val_mean_absolute_error: 64.1887\n",
            "Epoch 404/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.9191 - mean_absolute_error: 50.9191 - val_loss: 63.8508 - val_mean_absolute_error: 63.8508\n",
            "Epoch 405/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.9178 - mean_absolute_error: 50.9178 - val_loss: 63.9458 - val_mean_absolute_error: 63.9458\n",
            "Epoch 406/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.9164 - mean_absolute_error: 50.9164 - val_loss: 63.9779 - val_mean_absolute_error: 63.9779\n",
            "Epoch 407/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.9160 - mean_absolute_error: 50.9160 - val_loss: 63.6608 - val_mean_absolute_error: 63.6608\n",
            "Epoch 408/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.9144 - mean_absolute_error: 50.9144 - val_loss: 63.9593 - val_mean_absolute_error: 63.9593\n",
            "Epoch 409/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.9134 - mean_absolute_error: 50.9134 - val_loss: 63.8018 - val_mean_absolute_error: 63.8018\n",
            "Epoch 410/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.9120 - mean_absolute_error: 50.9120 - val_loss: 63.9132 - val_mean_absolute_error: 63.9132\n",
            "Epoch 411/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.9112 - mean_absolute_error: 50.9112 - val_loss: 64.1029 - val_mean_absolute_error: 64.1029\n",
            "Epoch 412/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.9099 - mean_absolute_error: 50.9099 - val_loss: 63.5581 - val_mean_absolute_error: 63.5581\n",
            "Epoch 413/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.9087 - mean_absolute_error: 50.9087 - val_loss: 64.1029 - val_mean_absolute_error: 64.1029\n",
            "Epoch 414/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.9078 - mean_absolute_error: 50.9078 - val_loss: 63.6518 - val_mean_absolute_error: 63.6518\n",
            "Epoch 415/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.9068 - mean_absolute_error: 50.9068 - val_loss: 63.6712 - val_mean_absolute_error: 63.6712\n",
            "Epoch 416/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.9058 - mean_absolute_error: 50.9058 - val_loss: 64.0503 - val_mean_absolute_error: 64.0503\n",
            "Epoch 417/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.9045 - mean_absolute_error: 50.9045 - val_loss: 63.8428 - val_mean_absolute_error: 63.8428\n",
            "Epoch 418/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.9037 - mean_absolute_error: 50.9037 - val_loss: 63.6608 - val_mean_absolute_error: 63.6608\n",
            "Epoch 419/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.9024 - mean_absolute_error: 50.9024 - val_loss: 63.6526 - val_mean_absolute_error: 63.6526\n",
            "Epoch 420/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.9015 - mean_absolute_error: 50.9015 - val_loss: 64.0228 - val_mean_absolute_error: 64.0228\n",
            "Epoch 421/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.9003 - mean_absolute_error: 50.9003 - val_loss: 64.0005 - val_mean_absolute_error: 64.0005\n",
            "Epoch 422/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.8992 - mean_absolute_error: 50.8992 - val_loss: 63.9474 - val_mean_absolute_error: 63.9474\n",
            "Epoch 423/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.8983 - mean_absolute_error: 50.8983 - val_loss: 63.8388 - val_mean_absolute_error: 63.8388\n",
            "Epoch 424/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.8972 - mean_absolute_error: 50.8972 - val_loss: 63.9340 - val_mean_absolute_error: 63.9340\n",
            "Epoch 425/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.8963 - mean_absolute_error: 50.8963 - val_loss: 63.7388 - val_mean_absolute_error: 63.7388\n",
            "Epoch 426/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.8948 - mean_absolute_error: 50.8948 - val_loss: 64.0965 - val_mean_absolute_error: 64.0965\n",
            "Epoch 427/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.8939 - mean_absolute_error: 50.8939 - val_loss: 64.0840 - val_mean_absolute_error: 64.0840\n",
            "Epoch 428/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.8929 - mean_absolute_error: 50.8929 - val_loss: 64.0666 - val_mean_absolute_error: 64.0666\n",
            "Epoch 429/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.8919 - mean_absolute_error: 50.8919 - val_loss: 63.5566 - val_mean_absolute_error: 63.5566\n",
            "Epoch 430/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.8910 - mean_absolute_error: 50.8910 - val_loss: 63.5395 - val_mean_absolute_error: 63.5395\n",
            "Epoch 431/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.8902 - mean_absolute_error: 50.8902 - val_loss: 63.6244 - val_mean_absolute_error: 63.6244\n",
            "Epoch 432/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.8890 - mean_absolute_error: 50.8890 - val_loss: 63.7891 - val_mean_absolute_error: 63.7891\n",
            "Epoch 433/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.8880 - mean_absolute_error: 50.8880 - val_loss: 63.6483 - val_mean_absolute_error: 63.6483\n",
            "Epoch 434/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.8870 - mean_absolute_error: 50.8870 - val_loss: 63.3200 - val_mean_absolute_error: 63.3200\n",
            "Epoch 435/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.8859 - mean_absolute_error: 50.8859 - val_loss: 63.8113 - val_mean_absolute_error: 63.8113\n",
            "Epoch 436/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.8850 - mean_absolute_error: 50.8850 - val_loss: 63.9285 - val_mean_absolute_error: 63.9285\n",
            "Epoch 437/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.8842 - mean_absolute_error: 50.8842 - val_loss: 63.8254 - val_mean_absolute_error: 63.8254\n",
            "Epoch 438/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.8831 - mean_absolute_error: 50.8831 - val_loss: 63.9643 - val_mean_absolute_error: 63.9643\n",
            "Epoch 439/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.8822 - mean_absolute_error: 50.8822 - val_loss: 63.9674 - val_mean_absolute_error: 63.9674\n",
            "Epoch 440/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.8812 - mean_absolute_error: 50.8812 - val_loss: 63.8447 - val_mean_absolute_error: 63.8447\n",
            "Epoch 441/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.8801 - mean_absolute_error: 50.8801 - val_loss: 64.0744 - val_mean_absolute_error: 64.0744\n",
            "Epoch 442/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.8792 - mean_absolute_error: 50.8792 - val_loss: 63.8298 - val_mean_absolute_error: 63.8298\n",
            "Epoch 443/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.8780 - mean_absolute_error: 50.8780 - val_loss: 63.6816 - val_mean_absolute_error: 63.6816\n",
            "Epoch 444/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.8770 - mean_absolute_error: 50.8770 - val_loss: 63.8216 - val_mean_absolute_error: 63.8216\n",
            "Epoch 445/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.8762 - mean_absolute_error: 50.8762 - val_loss: 63.6885 - val_mean_absolute_error: 63.6885\n",
            "Epoch 446/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.8754 - mean_absolute_error: 50.8754 - val_loss: 63.7039 - val_mean_absolute_error: 63.7039\n",
            "Epoch 447/1000\n",
            "769500/769500 [==============================] - 1s 2us/step - loss: 50.8743 - mean_absolute_error: 50.8743 - val_loss: 63.6650 - val_mean_absolute_error: 63.6650\n",
            "Epoch 448/1000\n",
            "769500/769500 [==============================] - 1s 2us/step - loss: 50.8735 - mean_absolute_error: 50.8735 - val_loss: 63.4548 - val_mean_absolute_error: 63.4548\n",
            "Epoch 449/1000\n",
            "769500/769500 [==============================] - 1s 2us/step - loss: 50.8721 - mean_absolute_error: 50.8721 - val_loss: 64.1836 - val_mean_absolute_error: 64.1836\n",
            "Epoch 450/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.8712 - mean_absolute_error: 50.8712 - val_loss: 63.5539 - val_mean_absolute_error: 63.5539\n",
            "Epoch 451/1000\n",
            "769500/769500 [==============================] - 1s 2us/step - loss: 50.8702 - mean_absolute_error: 50.8702 - val_loss: 63.6522 - val_mean_absolute_error: 63.6522\n",
            "Epoch 452/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.8691 - mean_absolute_error: 50.8691 - val_loss: 63.8444 - val_mean_absolute_error: 63.8444\n",
            "Epoch 453/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.8680 - mean_absolute_error: 50.8680 - val_loss: 63.5978 - val_mean_absolute_error: 63.5978\n",
            "Epoch 454/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.8673 - mean_absolute_error: 50.8673 - val_loss: 63.8224 - val_mean_absolute_error: 63.8224\n",
            "Epoch 455/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.8663 - mean_absolute_error: 50.8663 - val_loss: 63.9528 - val_mean_absolute_error: 63.9528\n",
            "Epoch 456/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.8650 - mean_absolute_error: 50.8650 - val_loss: 63.8813 - val_mean_absolute_error: 63.8813\n",
            "Epoch 457/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.8638 - mean_absolute_error: 50.8638 - val_loss: 64.1226 - val_mean_absolute_error: 64.1226\n",
            "Epoch 458/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.8634 - mean_absolute_error: 50.8634 - val_loss: 63.9529 - val_mean_absolute_error: 63.9529\n",
            "Epoch 459/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.8619 - mean_absolute_error: 50.8619 - val_loss: 63.8376 - val_mean_absolute_error: 63.8376\n",
            "Epoch 460/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.8613 - mean_absolute_error: 50.8613 - val_loss: 63.7125 - val_mean_absolute_error: 63.7125\n",
            "Epoch 461/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.8598 - mean_absolute_error: 50.8598 - val_loss: 64.0863 - val_mean_absolute_error: 64.0863\n",
            "Epoch 462/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.8589 - mean_absolute_error: 50.8589 - val_loss: 63.6619 - val_mean_absolute_error: 63.6619\n",
            "Epoch 463/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.8584 - mean_absolute_error: 50.8584 - val_loss: 63.7146 - val_mean_absolute_error: 63.7146\n",
            "Epoch 464/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.8565 - mean_absolute_error: 50.8565 - val_loss: 64.0298 - val_mean_absolute_error: 64.0298\n",
            "Epoch 465/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.8564 - mean_absolute_error: 50.8564 - val_loss: 63.7949 - val_mean_absolute_error: 63.7949\n",
            "Epoch 466/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.8552 - mean_absolute_error: 50.8552 - val_loss: 63.8056 - val_mean_absolute_error: 63.8056\n",
            "Epoch 467/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.8543 - mean_absolute_error: 50.8543 - val_loss: 63.8359 - val_mean_absolute_error: 63.8359\n",
            "Epoch 468/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.8529 - mean_absolute_error: 50.8529 - val_loss: 63.7443 - val_mean_absolute_error: 63.7443\n",
            "Epoch 469/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.8515 - mean_absolute_error: 50.8515 - val_loss: 63.7675 - val_mean_absolute_error: 63.7675\n",
            "Epoch 470/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.8510 - mean_absolute_error: 50.8510 - val_loss: 63.8149 - val_mean_absolute_error: 63.8149\n",
            "Epoch 471/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.8499 - mean_absolute_error: 50.8499 - val_loss: 63.9944 - val_mean_absolute_error: 63.9944\n",
            "Epoch 472/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.8494 - mean_absolute_error: 50.8494 - val_loss: 63.9077 - val_mean_absolute_error: 63.9077\n",
            "Epoch 473/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.8480 - mean_absolute_error: 50.8480 - val_loss: 63.7314 - val_mean_absolute_error: 63.7314\n",
            "Epoch 474/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.8472 - mean_absolute_error: 50.8472 - val_loss: 63.4907 - val_mean_absolute_error: 63.4907\n",
            "Epoch 475/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.8462 - mean_absolute_error: 50.8462 - val_loss: 64.0798 - val_mean_absolute_error: 64.0798\n",
            "Epoch 476/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.8455 - mean_absolute_error: 50.8455 - val_loss: 63.6043 - val_mean_absolute_error: 63.6043\n",
            "Epoch 477/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.8443 - mean_absolute_error: 50.8443 - val_loss: 63.7503 - val_mean_absolute_error: 63.7503\n",
            "Epoch 478/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.8429 - mean_absolute_error: 50.8429 - val_loss: 63.7003 - val_mean_absolute_error: 63.7003\n",
            "Epoch 479/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.8422 - mean_absolute_error: 50.8422 - val_loss: 63.6672 - val_mean_absolute_error: 63.6672\n",
            "Epoch 480/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.8414 - mean_absolute_error: 50.8414 - val_loss: 64.1322 - val_mean_absolute_error: 64.1322\n",
            "Epoch 481/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.8400 - mean_absolute_error: 50.8400 - val_loss: 63.9093 - val_mean_absolute_error: 63.9093\n",
            "Epoch 482/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.8387 - mean_absolute_error: 50.8387 - val_loss: 63.9170 - val_mean_absolute_error: 63.9170\n",
            "Epoch 483/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.8381 - mean_absolute_error: 50.8381 - val_loss: 63.6216 - val_mean_absolute_error: 63.6216\n",
            "Epoch 484/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.8369 - mean_absolute_error: 50.8369 - val_loss: 63.9012 - val_mean_absolute_error: 63.9012\n",
            "Epoch 485/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.8358 - mean_absolute_error: 50.8358 - val_loss: 63.6498 - val_mean_absolute_error: 63.6498\n",
            "Epoch 486/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.8344 - mean_absolute_error: 50.8344 - val_loss: 63.6030 - val_mean_absolute_error: 63.6030\n",
            "Epoch 487/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.8339 - mean_absolute_error: 50.8339 - val_loss: 63.6879 - val_mean_absolute_error: 63.6879\n",
            "Epoch 488/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.8328 - mean_absolute_error: 50.8328 - val_loss: 63.7298 - val_mean_absolute_error: 63.7298\n",
            "Epoch 489/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.8315 - mean_absolute_error: 50.8315 - val_loss: 63.3912 - val_mean_absolute_error: 63.3912\n",
            "Epoch 490/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.8304 - mean_absolute_error: 50.8304 - val_loss: 63.7521 - val_mean_absolute_error: 63.7521\n",
            "Epoch 491/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.8296 - mean_absolute_error: 50.8296 - val_loss: 63.3902 - val_mean_absolute_error: 63.3902\n",
            "Epoch 492/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.8285 - mean_absolute_error: 50.8285 - val_loss: 63.5400 - val_mean_absolute_error: 63.5400\n",
            "Epoch 493/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.8275 - mean_absolute_error: 50.8275 - val_loss: 63.8105 - val_mean_absolute_error: 63.8105\n",
            "Epoch 494/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.8265 - mean_absolute_error: 50.8265 - val_loss: 63.6772 - val_mean_absolute_error: 63.6772\n",
            "Epoch 495/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.8251 - mean_absolute_error: 50.8251 - val_loss: 63.6274 - val_mean_absolute_error: 63.6274\n",
            "Epoch 496/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.8242 - mean_absolute_error: 50.8242 - val_loss: 63.6559 - val_mean_absolute_error: 63.6559\n",
            "Epoch 497/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.8233 - mean_absolute_error: 50.8233 - val_loss: 63.4264 - val_mean_absolute_error: 63.4264\n",
            "Epoch 498/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.8219 - mean_absolute_error: 50.8219 - val_loss: 63.8208 - val_mean_absolute_error: 63.8208\n",
            "Epoch 499/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.8213 - mean_absolute_error: 50.8213 - val_loss: 63.4165 - val_mean_absolute_error: 63.4165\n",
            "Epoch 500/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.8201 - mean_absolute_error: 50.8201 - val_loss: 63.7222 - val_mean_absolute_error: 63.7222\n",
            "Epoch 501/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.8190 - mean_absolute_error: 50.8190 - val_loss: 63.4122 - val_mean_absolute_error: 63.4122\n",
            "Epoch 502/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.8174 - mean_absolute_error: 50.8174 - val_loss: 63.8909 - val_mean_absolute_error: 63.8909\n",
            "Epoch 503/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.8166 - mean_absolute_error: 50.8166 - val_loss: 63.7449 - val_mean_absolute_error: 63.7449\n",
            "Epoch 504/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.8159 - mean_absolute_error: 50.8159 - val_loss: 63.8317 - val_mean_absolute_error: 63.8317\n",
            "Epoch 505/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.8144 - mean_absolute_error: 50.8144 - val_loss: 63.5867 - val_mean_absolute_error: 63.5867\n",
            "Epoch 506/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.8133 - mean_absolute_error: 50.8133 - val_loss: 63.6021 - val_mean_absolute_error: 63.6021\n",
            "Epoch 507/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.8123 - mean_absolute_error: 50.8123 - val_loss: 63.6561 - val_mean_absolute_error: 63.6561\n",
            "Epoch 508/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.8114 - mean_absolute_error: 50.8114 - val_loss: 63.7638 - val_mean_absolute_error: 63.7638\n",
            "Epoch 509/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.8102 - mean_absolute_error: 50.8102 - val_loss: 63.4932 - val_mean_absolute_error: 63.4932\n",
            "Epoch 510/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.8094 - mean_absolute_error: 50.8094 - val_loss: 63.6936 - val_mean_absolute_error: 63.6936\n",
            "Epoch 511/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.8076 - mean_absolute_error: 50.8076 - val_loss: 63.7090 - val_mean_absolute_error: 63.7090\n",
            "Epoch 512/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.8067 - mean_absolute_error: 50.8067 - val_loss: 63.7710 - val_mean_absolute_error: 63.7710\n",
            "Epoch 513/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.8055 - mean_absolute_error: 50.8055 - val_loss: 63.2591 - val_mean_absolute_error: 63.2591\n",
            "Epoch 514/1000\n",
            "769500/769500 [==============================] - 1s 2us/step - loss: 50.8049 - mean_absolute_error: 50.8049 - val_loss: 63.7707 - val_mean_absolute_error: 63.7707\n",
            "Epoch 515/1000\n",
            "769500/769500 [==============================] - 1s 2us/step - loss: 50.8034 - mean_absolute_error: 50.8034 - val_loss: 63.6751 - val_mean_absolute_error: 63.6751\n",
            "Epoch 516/1000\n",
            "769500/769500 [==============================] - 1s 2us/step - loss: 50.8024 - mean_absolute_error: 50.8024 - val_loss: 63.7744 - val_mean_absolute_error: 63.7744\n",
            "Epoch 517/1000\n",
            "769500/769500 [==============================] - 1s 2us/step - loss: 50.8012 - mean_absolute_error: 50.8012 - val_loss: 63.4094 - val_mean_absolute_error: 63.4094\n",
            "Epoch 518/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.8003 - mean_absolute_error: 50.8003 - val_loss: 63.6200 - val_mean_absolute_error: 63.6200\n",
            "Epoch 519/1000\n",
            "769500/769500 [==============================] - 1s 2us/step - loss: 50.7990 - mean_absolute_error: 50.7990 - val_loss: 63.4401 - val_mean_absolute_error: 63.4401\n",
            "Epoch 520/1000\n",
            "769500/769500 [==============================] - 1s 2us/step - loss: 50.7981 - mean_absolute_error: 50.7981 - val_loss: 63.6676 - val_mean_absolute_error: 63.6676\n",
            "Epoch 521/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.7967 - mean_absolute_error: 50.7967 - val_loss: 63.5946 - val_mean_absolute_error: 63.5946\n",
            "Epoch 522/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.7952 - mean_absolute_error: 50.7952 - val_loss: 63.3708 - val_mean_absolute_error: 63.3708\n",
            "Epoch 523/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.7941 - mean_absolute_error: 50.7941 - val_loss: 63.5994 - val_mean_absolute_error: 63.5994\n",
            "Epoch 524/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.7934 - mean_absolute_error: 50.7934 - val_loss: 63.7450 - val_mean_absolute_error: 63.7450\n",
            "Epoch 525/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.7919 - mean_absolute_error: 50.7919 - val_loss: 63.6222 - val_mean_absolute_error: 63.6222\n",
            "Epoch 526/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.7901 - mean_absolute_error: 50.7901 - val_loss: 63.6152 - val_mean_absolute_error: 63.6152\n",
            "Epoch 527/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.7890 - mean_absolute_error: 50.7890 - val_loss: 63.1506 - val_mean_absolute_error: 63.1506\n",
            "Epoch 528/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.7874 - mean_absolute_error: 50.7874 - val_loss: 63.7118 - val_mean_absolute_error: 63.7118\n",
            "Epoch 529/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.7863 - mean_absolute_error: 50.7863 - val_loss: 63.2716 - val_mean_absolute_error: 63.2716\n",
            "Epoch 530/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.7846 - mean_absolute_error: 50.7846 - val_loss: 63.4348 - val_mean_absolute_error: 63.4348\n",
            "Epoch 531/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.7828 - mean_absolute_error: 50.7828 - val_loss: 63.3747 - val_mean_absolute_error: 63.3747\n",
            "Epoch 532/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.7814 - mean_absolute_error: 50.7814 - val_loss: 63.7176 - val_mean_absolute_error: 63.7176\n",
            "Epoch 533/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.7797 - mean_absolute_error: 50.7797 - val_loss: 63.4055 - val_mean_absolute_error: 63.4055\n",
            "Epoch 534/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.7780 - mean_absolute_error: 50.7780 - val_loss: 63.3564 - val_mean_absolute_error: 63.3564\n",
            "Epoch 535/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.7765 - mean_absolute_error: 50.7765 - val_loss: 63.7849 - val_mean_absolute_error: 63.7849\n",
            "Epoch 536/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.7742 - mean_absolute_error: 50.7742 - val_loss: 63.5324 - val_mean_absolute_error: 63.5324\n",
            "Epoch 537/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.7728 - mean_absolute_error: 50.7728 - val_loss: 63.5351 - val_mean_absolute_error: 63.5351\n",
            "Epoch 538/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.7709 - mean_absolute_error: 50.7709 - val_loss: 63.4906 - val_mean_absolute_error: 63.4906\n",
            "Epoch 539/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.7681 - mean_absolute_error: 50.7681 - val_loss: 63.1867 - val_mean_absolute_error: 63.1867\n",
            "Epoch 540/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.7665 - mean_absolute_error: 50.7665 - val_loss: 63.5236 - val_mean_absolute_error: 63.5236\n",
            "Epoch 541/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.7645 - mean_absolute_error: 50.7645 - val_loss: 63.5281 - val_mean_absolute_error: 63.5281\n",
            "Epoch 542/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.7623 - mean_absolute_error: 50.7623 - val_loss: 63.5942 - val_mean_absolute_error: 63.5942\n",
            "Epoch 543/1000\n",
            "769500/769500 [==============================] - 1s 2us/step - loss: 50.7599 - mean_absolute_error: 50.7599 - val_loss: 63.4080 - val_mean_absolute_error: 63.4080\n",
            "Epoch 544/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.7574 - mean_absolute_error: 50.7574 - val_loss: 63.2835 - val_mean_absolute_error: 63.2835\n",
            "Epoch 545/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.7552 - mean_absolute_error: 50.7552 - val_loss: 63.3073 - val_mean_absolute_error: 63.3073\n",
            "Epoch 546/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.7532 - mean_absolute_error: 50.7532 - val_loss: 63.3527 - val_mean_absolute_error: 63.3527\n",
            "Epoch 547/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.7510 - mean_absolute_error: 50.7510 - val_loss: 63.2601 - val_mean_absolute_error: 63.2601\n",
            "Epoch 548/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.7486 - mean_absolute_error: 50.7486 - val_loss: 63.5726 - val_mean_absolute_error: 63.5726\n",
            "Epoch 549/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.7466 - mean_absolute_error: 50.7466 - val_loss: 63.4800 - val_mean_absolute_error: 63.4800\n",
            "Epoch 550/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.7437 - mean_absolute_error: 50.7437 - val_loss: 63.9386 - val_mean_absolute_error: 63.9386\n",
            "Epoch 551/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.7424 - mean_absolute_error: 50.7424 - val_loss: 63.5892 - val_mean_absolute_error: 63.5892\n",
            "Epoch 552/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.7398 - mean_absolute_error: 50.7398 - val_loss: 63.3367 - val_mean_absolute_error: 63.3367\n",
            "Epoch 553/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.7377 - mean_absolute_error: 50.7377 - val_loss: 63.8039 - val_mean_absolute_error: 63.8039\n",
            "Epoch 554/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.7360 - mean_absolute_error: 50.7360 - val_loss: 63.7221 - val_mean_absolute_error: 63.7221\n",
            "Epoch 555/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.7335 - mean_absolute_error: 50.7335 - val_loss: 63.6005 - val_mean_absolute_error: 63.6005\n",
            "Epoch 556/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.7312 - mean_absolute_error: 50.7312 - val_loss: 63.6142 - val_mean_absolute_error: 63.6142\n",
            "Epoch 557/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.7297 - mean_absolute_error: 50.7297 - val_loss: 63.6879 - val_mean_absolute_error: 63.6879\n",
            "Epoch 558/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.7275 - mean_absolute_error: 50.7275 - val_loss: 63.6785 - val_mean_absolute_error: 63.6785\n",
            "Epoch 559/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.7259 - mean_absolute_error: 50.7259 - val_loss: 63.3117 - val_mean_absolute_error: 63.3117\n",
            "Epoch 560/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.7238 - mean_absolute_error: 50.7238 - val_loss: 63.3201 - val_mean_absolute_error: 63.3201\n",
            "Epoch 561/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.7220 - mean_absolute_error: 50.7220 - val_loss: 63.5170 - val_mean_absolute_error: 63.5170\n",
            "Epoch 562/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.7206 - mean_absolute_error: 50.7206 - val_loss: 63.5261 - val_mean_absolute_error: 63.5261\n",
            "Epoch 563/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.7182 - mean_absolute_error: 50.7182 - val_loss: 63.4257 - val_mean_absolute_error: 63.4257\n",
            "Epoch 564/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.7165 - mean_absolute_error: 50.7165 - val_loss: 63.4773 - val_mean_absolute_error: 63.4773\n",
            "Epoch 565/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.7149 - mean_absolute_error: 50.7149 - val_loss: 63.6351 - val_mean_absolute_error: 63.6351\n",
            "Epoch 566/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.7130 - mean_absolute_error: 50.7130 - val_loss: 63.4770 - val_mean_absolute_error: 63.4770\n",
            "Epoch 567/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.7113 - mean_absolute_error: 50.7113 - val_loss: 63.4507 - val_mean_absolute_error: 63.4507\n",
            "Epoch 568/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.7096 - mean_absolute_error: 50.7096 - val_loss: 63.5427 - val_mean_absolute_error: 63.5427\n",
            "Epoch 569/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.7079 - mean_absolute_error: 50.7079 - val_loss: 63.6977 - val_mean_absolute_error: 63.6977\n",
            "Epoch 570/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.7067 - mean_absolute_error: 50.7067 - val_loss: 63.6276 - val_mean_absolute_error: 63.6276\n",
            "Epoch 571/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.7048 - mean_absolute_error: 50.7048 - val_loss: 63.3594 - val_mean_absolute_error: 63.3594\n",
            "Epoch 572/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.7031 - mean_absolute_error: 50.7031 - val_loss: 63.3685 - val_mean_absolute_error: 63.3685\n",
            "Epoch 573/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.7020 - mean_absolute_error: 50.7020 - val_loss: 63.2690 - val_mean_absolute_error: 63.2690\n",
            "Epoch 574/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.7007 - mean_absolute_error: 50.7007 - val_loss: 63.3431 - val_mean_absolute_error: 63.3431\n",
            "Epoch 575/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6988 - mean_absolute_error: 50.6988 - val_loss: 63.6860 - val_mean_absolute_error: 63.6860\n",
            "Epoch 576/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6972 - mean_absolute_error: 50.6972 - val_loss: 63.4685 - val_mean_absolute_error: 63.4685\n",
            "Epoch 577/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6958 - mean_absolute_error: 50.6958 - val_loss: 63.0970 - val_mean_absolute_error: 63.0970\n",
            "Epoch 578/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6943 - mean_absolute_error: 50.6943 - val_loss: 63.2661 - val_mean_absolute_error: 63.2661\n",
            "Epoch 579/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6930 - mean_absolute_error: 50.6930 - val_loss: 63.7196 - val_mean_absolute_error: 63.7196\n",
            "Epoch 580/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6918 - mean_absolute_error: 50.6918 - val_loss: 63.3583 - val_mean_absolute_error: 63.3583\n",
            "Epoch 581/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6903 - mean_absolute_error: 50.6903 - val_loss: 63.5913 - val_mean_absolute_error: 63.5913\n",
            "Epoch 582/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6883 - mean_absolute_error: 50.6883 - val_loss: 63.1515 - val_mean_absolute_error: 63.1515\n",
            "Epoch 583/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6875 - mean_absolute_error: 50.6875 - val_loss: 63.0209 - val_mean_absolute_error: 63.0209\n",
            "Epoch 584/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6863 - mean_absolute_error: 50.6863 - val_loss: 63.3477 - val_mean_absolute_error: 63.3477\n",
            "Epoch 585/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6851 - mean_absolute_error: 50.6851 - val_loss: 63.1805 - val_mean_absolute_error: 63.1805\n",
            "Epoch 586/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6840 - mean_absolute_error: 50.6840 - val_loss: 63.6970 - val_mean_absolute_error: 63.6970\n",
            "Epoch 587/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6827 - mean_absolute_error: 50.6827 - val_loss: 63.3537 - val_mean_absolute_error: 63.3537\n",
            "Epoch 588/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6815 - mean_absolute_error: 50.6815 - val_loss: 63.0724 - val_mean_absolute_error: 63.0724\n",
            "Epoch 589/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6806 - mean_absolute_error: 50.6806 - val_loss: 63.5405 - val_mean_absolute_error: 63.5405\n",
            "Epoch 590/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6794 - mean_absolute_error: 50.6794 - val_loss: 63.4851 - val_mean_absolute_error: 63.4851\n",
            "Epoch 591/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6782 - mean_absolute_error: 50.6782 - val_loss: 63.2246 - val_mean_absolute_error: 63.2246\n",
            "Epoch 592/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6771 - mean_absolute_error: 50.6771 - val_loss: 63.4837 - val_mean_absolute_error: 63.4837\n",
            "Epoch 593/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6762 - mean_absolute_error: 50.6762 - val_loss: 63.3595 - val_mean_absolute_error: 63.3595\n",
            "Epoch 594/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6753 - mean_absolute_error: 50.6753 - val_loss: 63.3189 - val_mean_absolute_error: 63.3189\n",
            "Epoch 595/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6739 - mean_absolute_error: 50.6739 - val_loss: 63.5711 - val_mean_absolute_error: 63.5711\n",
            "Epoch 596/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6730 - mean_absolute_error: 50.6730 - val_loss: 63.1904 - val_mean_absolute_error: 63.1904\n",
            "Epoch 597/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6716 - mean_absolute_error: 50.6716 - val_loss: 63.2891 - val_mean_absolute_error: 63.2891\n",
            "Epoch 598/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6710 - mean_absolute_error: 50.6710 - val_loss: 63.4155 - val_mean_absolute_error: 63.4155\n",
            "Epoch 599/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6705 - mean_absolute_error: 50.6705 - val_loss: 63.5423 - val_mean_absolute_error: 63.5423\n",
            "Epoch 600/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6689 - mean_absolute_error: 50.6689 - val_loss: 63.3965 - val_mean_absolute_error: 63.3965\n",
            "Epoch 601/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6679 - mean_absolute_error: 50.6679 - val_loss: 63.3692 - val_mean_absolute_error: 63.3692\n",
            "Epoch 602/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6675 - mean_absolute_error: 50.6675 - val_loss: 63.2811 - val_mean_absolute_error: 63.2811\n",
            "Epoch 603/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6660 - mean_absolute_error: 50.6660 - val_loss: 63.6279 - val_mean_absolute_error: 63.6279\n",
            "Epoch 604/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6654 - mean_absolute_error: 50.6654 - val_loss: 63.6698 - val_mean_absolute_error: 63.6698\n",
            "Epoch 605/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6647 - mean_absolute_error: 50.6647 - val_loss: 63.2544 - val_mean_absolute_error: 63.2544\n",
            "Epoch 606/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6631 - mean_absolute_error: 50.6631 - val_loss: 63.2022 - val_mean_absolute_error: 63.2022\n",
            "Epoch 607/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6625 - mean_absolute_error: 50.6625 - val_loss: 63.0656 - val_mean_absolute_error: 63.0656\n",
            "Epoch 608/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6620 - mean_absolute_error: 50.6620 - val_loss: 63.5516 - val_mean_absolute_error: 63.5516\n",
            "Epoch 609/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6613 - mean_absolute_error: 50.6613 - val_loss: 63.3582 - val_mean_absolute_error: 63.3582\n",
            "Epoch 610/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6600 - mean_absolute_error: 50.6600 - val_loss: 63.5151 - val_mean_absolute_error: 63.5151\n",
            "Epoch 611/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6594 - mean_absolute_error: 50.6594 - val_loss: 63.4249 - val_mean_absolute_error: 63.4249\n",
            "Epoch 612/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6583 - mean_absolute_error: 50.6583 - val_loss: 63.1549 - val_mean_absolute_error: 63.1549\n",
            "Epoch 613/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6573 - mean_absolute_error: 50.6573 - val_loss: 63.3738 - val_mean_absolute_error: 63.3738\n",
            "Epoch 614/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6567 - mean_absolute_error: 50.6567 - val_loss: 63.0665 - val_mean_absolute_error: 63.0665\n",
            "Epoch 615/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6561 - mean_absolute_error: 50.6561 - val_loss: 63.2950 - val_mean_absolute_error: 63.2950\n",
            "Epoch 616/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6553 - mean_absolute_error: 50.6553 - val_loss: 63.3119 - val_mean_absolute_error: 63.3119\n",
            "Epoch 617/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6541 - mean_absolute_error: 50.6541 - val_loss: 63.2627 - val_mean_absolute_error: 63.2627\n",
            "Epoch 618/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6539 - mean_absolute_error: 50.6539 - val_loss: 63.3929 - val_mean_absolute_error: 63.3929\n",
            "Epoch 619/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6527 - mean_absolute_error: 50.6527 - val_loss: 63.1775 - val_mean_absolute_error: 63.1775\n",
            "Epoch 620/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6524 - mean_absolute_error: 50.6524 - val_loss: 63.4330 - val_mean_absolute_error: 63.4330\n",
            "Epoch 621/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6510 - mean_absolute_error: 50.6510 - val_loss: 63.4428 - val_mean_absolute_error: 63.4428\n",
            "Epoch 622/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6506 - mean_absolute_error: 50.6506 - val_loss: 63.2813 - val_mean_absolute_error: 63.2813\n",
            "Epoch 623/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6495 - mean_absolute_error: 50.6495 - val_loss: 63.1815 - val_mean_absolute_error: 63.1815\n",
            "Epoch 624/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6492 - mean_absolute_error: 50.6492 - val_loss: 63.2376 - val_mean_absolute_error: 63.2376\n",
            "Epoch 625/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6487 - mean_absolute_error: 50.6487 - val_loss: 63.1962 - val_mean_absolute_error: 63.1962\n",
            "Epoch 626/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6478 - mean_absolute_error: 50.6478 - val_loss: 63.3493 - val_mean_absolute_error: 63.3493\n",
            "Epoch 627/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6470 - mean_absolute_error: 50.6470 - val_loss: 63.3134 - val_mean_absolute_error: 63.3134\n",
            "Epoch 628/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6464 - mean_absolute_error: 50.6464 - val_loss: 63.1286 - val_mean_absolute_error: 63.1286\n",
            "Epoch 629/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6455 - mean_absolute_error: 50.6455 - val_loss: 63.0722 - val_mean_absolute_error: 63.0722\n",
            "Epoch 630/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6452 - mean_absolute_error: 50.6452 - val_loss: 63.5954 - val_mean_absolute_error: 63.5954\n",
            "Epoch 631/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6442 - mean_absolute_error: 50.6442 - val_loss: 63.1396 - val_mean_absolute_error: 63.1396\n",
            "Epoch 632/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6438 - mean_absolute_error: 50.6438 - val_loss: 63.1785 - val_mean_absolute_error: 63.1785\n",
            "Epoch 633/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6430 - mean_absolute_error: 50.6430 - val_loss: 63.3065 - val_mean_absolute_error: 63.3065\n",
            "Epoch 634/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6423 - mean_absolute_error: 50.6423 - val_loss: 63.4314 - val_mean_absolute_error: 63.4314\n",
            "Epoch 635/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6418 - mean_absolute_error: 50.6418 - val_loss: 63.1705 - val_mean_absolute_error: 63.1705\n",
            "Epoch 636/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6411 - mean_absolute_error: 50.6411 - val_loss: 63.1928 - val_mean_absolute_error: 63.1928\n",
            "Epoch 637/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6405 - mean_absolute_error: 50.6405 - val_loss: 63.5856 - val_mean_absolute_error: 63.5856\n",
            "Epoch 638/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6398 - mean_absolute_error: 50.6398 - val_loss: 63.5927 - val_mean_absolute_error: 63.5927\n",
            "Epoch 639/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6395 - mean_absolute_error: 50.6395 - val_loss: 63.3868 - val_mean_absolute_error: 63.3868\n",
            "Epoch 640/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6386 - mean_absolute_error: 50.6386 - val_loss: 63.3291 - val_mean_absolute_error: 63.3291\n",
            "Epoch 641/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6381 - mean_absolute_error: 50.6381 - val_loss: 63.0182 - val_mean_absolute_error: 63.0182\n",
            "Epoch 642/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6376 - mean_absolute_error: 50.6376 - val_loss: 63.3684 - val_mean_absolute_error: 63.3684\n",
            "Epoch 643/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6370 - mean_absolute_error: 50.6370 - val_loss: 63.0841 - val_mean_absolute_error: 63.0841\n",
            "Epoch 644/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6367 - mean_absolute_error: 50.6367 - val_loss: 63.2384 - val_mean_absolute_error: 63.2384\n",
            "Epoch 645/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6358 - mean_absolute_error: 50.6358 - val_loss: 63.2568 - val_mean_absolute_error: 63.2568\n",
            "Epoch 646/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6353 - mean_absolute_error: 50.6353 - val_loss: 63.2565 - val_mean_absolute_error: 63.2565\n",
            "Epoch 647/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6345 - mean_absolute_error: 50.6345 - val_loss: 63.3391 - val_mean_absolute_error: 63.3391\n",
            "Epoch 648/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6341 - mean_absolute_error: 50.6341 - val_loss: 63.3115 - val_mean_absolute_error: 63.3115\n",
            "Epoch 649/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6334 - mean_absolute_error: 50.6334 - val_loss: 63.2951 - val_mean_absolute_error: 63.2951\n",
            "Epoch 650/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6334 - mean_absolute_error: 50.6334 - val_loss: 63.1987 - val_mean_absolute_error: 63.1987\n",
            "Epoch 651/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6326 - mean_absolute_error: 50.6326 - val_loss: 63.2600 - val_mean_absolute_error: 63.2600\n",
            "Epoch 652/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6316 - mean_absolute_error: 50.6316 - val_loss: 63.7294 - val_mean_absolute_error: 63.7294\n",
            "Epoch 653/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6314 - mean_absolute_error: 50.6314 - val_loss: 63.4844 - val_mean_absolute_error: 63.4844\n",
            "Epoch 654/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6305 - mean_absolute_error: 50.6305 - val_loss: 63.4016 - val_mean_absolute_error: 63.4016\n",
            "Epoch 655/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6302 - mean_absolute_error: 50.6302 - val_loss: 63.3573 - val_mean_absolute_error: 63.3573\n",
            "Epoch 656/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6295 - mean_absolute_error: 50.6295 - val_loss: 63.1231 - val_mean_absolute_error: 63.1231\n",
            "Epoch 657/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6288 - mean_absolute_error: 50.6288 - val_loss: 63.3814 - val_mean_absolute_error: 63.3814\n",
            "Epoch 658/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6289 - mean_absolute_error: 50.6289 - val_loss: 62.9784 - val_mean_absolute_error: 62.9784\n",
            "Epoch 659/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6283 - mean_absolute_error: 50.6283 - val_loss: 63.1455 - val_mean_absolute_error: 63.1455\n",
            "Epoch 660/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6277 - mean_absolute_error: 50.6277 - val_loss: 63.3386 - val_mean_absolute_error: 63.3386\n",
            "Epoch 661/1000\n",
            "769500/769500 [==============================] - 1s 2us/step - loss: 50.6269 - mean_absolute_error: 50.6269 - val_loss: 63.2048 - val_mean_absolute_error: 63.2048\n",
            "Epoch 662/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6260 - mean_absolute_error: 50.6260 - val_loss: 63.1503 - val_mean_absolute_error: 63.1503\n",
            "Epoch 663/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6256 - mean_absolute_error: 50.6256 - val_loss: 63.2035 - val_mean_absolute_error: 63.2035\n",
            "Epoch 664/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6252 - mean_absolute_error: 50.6252 - val_loss: 63.6130 - val_mean_absolute_error: 63.6130\n",
            "Epoch 665/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6251 - mean_absolute_error: 50.6251 - val_loss: 63.3438 - val_mean_absolute_error: 63.3438\n",
            "Epoch 666/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6242 - mean_absolute_error: 50.6242 - val_loss: 63.4787 - val_mean_absolute_error: 63.4787\n",
            "Epoch 667/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6241 - mean_absolute_error: 50.6241 - val_loss: 63.5528 - val_mean_absolute_error: 63.5528\n",
            "Epoch 668/1000\n",
            "769500/769500 [==============================] - 1s 2us/step - loss: 50.6236 - mean_absolute_error: 50.6236 - val_loss: 63.1474 - val_mean_absolute_error: 63.1474\n",
            "Epoch 669/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6231 - mean_absolute_error: 50.6231 - val_loss: 63.4376 - val_mean_absolute_error: 63.4376\n",
            "Epoch 670/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6228 - mean_absolute_error: 50.6228 - val_loss: 63.1977 - val_mean_absolute_error: 63.1977\n",
            "Epoch 671/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6219 - mean_absolute_error: 50.6219 - val_loss: 63.1335 - val_mean_absolute_error: 63.1335\n",
            "Epoch 672/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6218 - mean_absolute_error: 50.6218 - val_loss: 63.4228 - val_mean_absolute_error: 63.4228\n",
            "Epoch 673/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6212 - mean_absolute_error: 50.6212 - val_loss: 62.9588 - val_mean_absolute_error: 62.9588\n",
            "Epoch 674/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6208 - mean_absolute_error: 50.6208 - val_loss: 63.3027 - val_mean_absolute_error: 63.3027\n",
            "Epoch 675/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6204 - mean_absolute_error: 50.6204 - val_loss: 63.1824 - val_mean_absolute_error: 63.1824\n",
            "Epoch 676/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6200 - mean_absolute_error: 50.6200 - val_loss: 63.3284 - val_mean_absolute_error: 63.3284\n",
            "Epoch 677/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6193 - mean_absolute_error: 50.6193 - val_loss: 63.4550 - val_mean_absolute_error: 63.4550\n",
            "Epoch 678/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6186 - mean_absolute_error: 50.6186 - val_loss: 63.1231 - val_mean_absolute_error: 63.1231\n",
            "Epoch 679/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6181 - mean_absolute_error: 50.6181 - val_loss: 63.3400 - val_mean_absolute_error: 63.3400\n",
            "Epoch 680/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6181 - mean_absolute_error: 50.6181 - val_loss: 63.4074 - val_mean_absolute_error: 63.4074\n",
            "Epoch 681/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6175 - mean_absolute_error: 50.6175 - val_loss: 62.8533 - val_mean_absolute_error: 62.8533\n",
            "Epoch 682/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6171 - mean_absolute_error: 50.6171 - val_loss: 63.2059 - val_mean_absolute_error: 63.2059\n",
            "Epoch 683/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6170 - mean_absolute_error: 50.6170 - val_loss: 63.1096 - val_mean_absolute_error: 63.1096\n",
            "Epoch 684/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6163 - mean_absolute_error: 50.6163 - val_loss: 63.3209 - val_mean_absolute_error: 63.3209\n",
            "Epoch 685/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6160 - mean_absolute_error: 50.6160 - val_loss: 63.3595 - val_mean_absolute_error: 63.3595\n",
            "Epoch 686/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6155 - mean_absolute_error: 50.6155 - val_loss: 63.1808 - val_mean_absolute_error: 63.1808\n",
            "Epoch 687/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6150 - mean_absolute_error: 50.6150 - val_loss: 63.0084 - val_mean_absolute_error: 63.0084\n",
            "Epoch 688/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6146 - mean_absolute_error: 50.6146 - val_loss: 63.0527 - val_mean_absolute_error: 63.0527\n",
            "Epoch 689/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6141 - mean_absolute_error: 50.6141 - val_loss: 62.7751 - val_mean_absolute_error: 62.7751\n",
            "Epoch 690/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6136 - mean_absolute_error: 50.6136 - val_loss: 63.3275 - val_mean_absolute_error: 63.3275\n",
            "Epoch 691/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6134 - mean_absolute_error: 50.6134 - val_loss: 63.2801 - val_mean_absolute_error: 63.2801\n",
            "Epoch 692/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6130 - mean_absolute_error: 50.6130 - val_loss: 63.3566 - val_mean_absolute_error: 63.3566\n",
            "Epoch 693/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6126 - mean_absolute_error: 50.6126 - val_loss: 63.3107 - val_mean_absolute_error: 63.3107\n",
            "Epoch 694/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6124 - mean_absolute_error: 50.6124 - val_loss: 63.0861 - val_mean_absolute_error: 63.0861\n",
            "Epoch 695/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6109 - mean_absolute_error: 50.6109 - val_loss: 62.9524 - val_mean_absolute_error: 62.9524\n",
            "Epoch 696/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6114 - mean_absolute_error: 50.6114 - val_loss: 63.3463 - val_mean_absolute_error: 63.3463\n",
            "Epoch 697/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6110 - mean_absolute_error: 50.6110 - val_loss: 63.1449 - val_mean_absolute_error: 63.1449\n",
            "Epoch 698/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6104 - mean_absolute_error: 50.6104 - val_loss: 63.1203 - val_mean_absolute_error: 63.1203\n",
            "Epoch 699/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6097 - mean_absolute_error: 50.6097 - val_loss: 63.2197 - val_mean_absolute_error: 63.2197\n",
            "Epoch 700/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6097 - mean_absolute_error: 50.6097 - val_loss: 63.1227 - val_mean_absolute_error: 63.1227\n",
            "Epoch 701/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6089 - mean_absolute_error: 50.6089 - val_loss: 63.1883 - val_mean_absolute_error: 63.1883\n",
            "Epoch 702/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6086 - mean_absolute_error: 50.6086 - val_loss: 63.2900 - val_mean_absolute_error: 63.2900\n",
            "Epoch 703/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6083 - mean_absolute_error: 50.6083 - val_loss: 62.9604 - val_mean_absolute_error: 62.9604\n",
            "Epoch 704/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6079 - mean_absolute_error: 50.6079 - val_loss: 63.2132 - val_mean_absolute_error: 63.2132\n",
            "Epoch 705/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6076 - mean_absolute_error: 50.6076 - val_loss: 63.1389 - val_mean_absolute_error: 63.1389\n",
            "Epoch 706/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6073 - mean_absolute_error: 50.6073 - val_loss: 63.3181 - val_mean_absolute_error: 63.3181\n",
            "Epoch 707/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6064 - mean_absolute_error: 50.6064 - val_loss: 63.3964 - val_mean_absolute_error: 63.3964\n",
            "Epoch 708/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6068 - mean_absolute_error: 50.6068 - val_loss: 63.3759 - val_mean_absolute_error: 63.3759\n",
            "Epoch 709/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6062 - mean_absolute_error: 50.6062 - val_loss: 63.1544 - val_mean_absolute_error: 63.1544\n",
            "Epoch 710/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6052 - mean_absolute_error: 50.6052 - val_loss: 63.2894 - val_mean_absolute_error: 63.2894\n",
            "Epoch 711/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6053 - mean_absolute_error: 50.6053 - val_loss: 63.4628 - val_mean_absolute_error: 63.4628\n",
            "Epoch 712/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6048 - mean_absolute_error: 50.6048 - val_loss: 63.4117 - val_mean_absolute_error: 63.4117\n",
            "Epoch 713/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6044 - mean_absolute_error: 50.6044 - val_loss: 63.3796 - val_mean_absolute_error: 63.3796\n",
            "Epoch 714/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6036 - mean_absolute_error: 50.6036 - val_loss: 63.2421 - val_mean_absolute_error: 63.2421\n",
            "Epoch 715/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6035 - mean_absolute_error: 50.6035 - val_loss: 63.5275 - val_mean_absolute_error: 63.5275\n",
            "Epoch 716/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6033 - mean_absolute_error: 50.6033 - val_loss: 63.3627 - val_mean_absolute_error: 63.3627\n",
            "Epoch 717/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6027 - mean_absolute_error: 50.6027 - val_loss: 63.4651 - val_mean_absolute_error: 63.4651\n",
            "Epoch 718/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6023 - mean_absolute_error: 50.6023 - val_loss: 63.3701 - val_mean_absolute_error: 63.3701\n",
            "Epoch 719/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6017 - mean_absolute_error: 50.6017 - val_loss: 62.9394 - val_mean_absolute_error: 62.9394\n",
            "Epoch 720/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6016 - mean_absolute_error: 50.6016 - val_loss: 63.1630 - val_mean_absolute_error: 63.1630\n",
            "Epoch 721/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6012 - mean_absolute_error: 50.6012 - val_loss: 63.4655 - val_mean_absolute_error: 63.4655\n",
            "Epoch 722/1000\n",
            "769500/769500 [==============================] - 1s 2us/step - loss: 50.6005 - mean_absolute_error: 50.6005 - val_loss: 63.4198 - val_mean_absolute_error: 63.4198\n",
            "Epoch 723/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6002 - mean_absolute_error: 50.6002 - val_loss: 62.8954 - val_mean_absolute_error: 62.8954\n",
            "Epoch 724/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.6000 - mean_absolute_error: 50.6000 - val_loss: 62.9577 - val_mean_absolute_error: 62.9577\n",
            "Epoch 725/1000\n",
            "769500/769500 [==============================] - 1s 2us/step - loss: 50.5998 - mean_absolute_error: 50.5998 - val_loss: 63.3140 - val_mean_absolute_error: 63.3140\n",
            "Epoch 726/1000\n",
            "769500/769500 [==============================] - 1s 2us/step - loss: 50.5992 - mean_absolute_error: 50.5992 - val_loss: 63.0887 - val_mean_absolute_error: 63.0887\n",
            "Epoch 727/1000\n",
            "769500/769500 [==============================] - 1s 2us/step - loss: 50.5987 - mean_absolute_error: 50.5987 - val_loss: 63.1099 - val_mean_absolute_error: 63.1099\n",
            "Epoch 728/1000\n",
            "769500/769500 [==============================] - 1s 2us/step - loss: 50.5986 - mean_absolute_error: 50.5986 - val_loss: 63.0056 - val_mean_absolute_error: 63.0056\n",
            "Epoch 729/1000\n",
            "769500/769500 [==============================] - 1s 2us/step - loss: 50.5979 - mean_absolute_error: 50.5979 - val_loss: 63.4743 - val_mean_absolute_error: 63.4743\n",
            "Epoch 730/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5980 - mean_absolute_error: 50.5980 - val_loss: 63.3583 - val_mean_absolute_error: 63.3583\n",
            "Epoch 731/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5973 - mean_absolute_error: 50.5973 - val_loss: 63.1977 - val_mean_absolute_error: 63.1977\n",
            "Epoch 732/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5971 - mean_absolute_error: 50.5971 - val_loss: 63.3437 - val_mean_absolute_error: 63.3437\n",
            "Epoch 733/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5965 - mean_absolute_error: 50.5965 - val_loss: 63.2492 - val_mean_absolute_error: 63.2492\n",
            "Epoch 734/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5963 - mean_absolute_error: 50.5963 - val_loss: 62.9725 - val_mean_absolute_error: 62.9725\n",
            "Epoch 735/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5958 - mean_absolute_error: 50.5958 - val_loss: 63.2575 - val_mean_absolute_error: 63.2575\n",
            "Epoch 736/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5957 - mean_absolute_error: 50.5957 - val_loss: 63.2193 - val_mean_absolute_error: 63.2193\n",
            "Epoch 737/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5952 - mean_absolute_error: 50.5952 - val_loss: 63.4497 - val_mean_absolute_error: 63.4497\n",
            "Epoch 738/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5945 - mean_absolute_error: 50.5945 - val_loss: 63.1873 - val_mean_absolute_error: 63.1873\n",
            "Epoch 739/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5944 - mean_absolute_error: 50.5944 - val_loss: 63.0787 - val_mean_absolute_error: 63.0787\n",
            "Epoch 740/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5941 - mean_absolute_error: 50.5941 - val_loss: 63.0168 - val_mean_absolute_error: 63.0168\n",
            "Epoch 741/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5938 - mean_absolute_error: 50.5938 - val_loss: 63.2625 - val_mean_absolute_error: 63.2625\n",
            "Epoch 742/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5931 - mean_absolute_error: 50.5931 - val_loss: 63.2613 - val_mean_absolute_error: 63.2613\n",
            "Epoch 743/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5934 - mean_absolute_error: 50.5934 - val_loss: 63.1560 - val_mean_absolute_error: 63.1560\n",
            "Epoch 744/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5928 - mean_absolute_error: 50.5928 - val_loss: 63.1441 - val_mean_absolute_error: 63.1441\n",
            "Epoch 745/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5922 - mean_absolute_error: 50.5922 - val_loss: 63.1427 - val_mean_absolute_error: 63.1427\n",
            "Epoch 746/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5924 - mean_absolute_error: 50.5924 - val_loss: 63.2762 - val_mean_absolute_error: 63.2762\n",
            "Epoch 747/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5920 - mean_absolute_error: 50.5920 - val_loss: 63.3169 - val_mean_absolute_error: 63.3169\n",
            "Epoch 748/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5912 - mean_absolute_error: 50.5912 - val_loss: 63.3157 - val_mean_absolute_error: 63.3157\n",
            "Epoch 749/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5907 - mean_absolute_error: 50.5907 - val_loss: 63.0117 - val_mean_absolute_error: 63.0117\n",
            "Epoch 750/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5904 - mean_absolute_error: 50.5904 - val_loss: 62.9428 - val_mean_absolute_error: 62.9428\n",
            "Epoch 751/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5902 - mean_absolute_error: 50.5902 - val_loss: 63.1871 - val_mean_absolute_error: 63.1871\n",
            "Epoch 752/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5896 - mean_absolute_error: 50.5896 - val_loss: 63.2498 - val_mean_absolute_error: 63.2498\n",
            "Epoch 753/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5894 - mean_absolute_error: 50.5894 - val_loss: 63.1922 - val_mean_absolute_error: 63.1922\n",
            "Epoch 754/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5890 - mean_absolute_error: 50.5890 - val_loss: 63.3266 - val_mean_absolute_error: 63.3266\n",
            "Epoch 755/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5888 - mean_absolute_error: 50.5888 - val_loss: 63.2671 - val_mean_absolute_error: 63.2671\n",
            "Epoch 756/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5886 - mean_absolute_error: 50.5886 - val_loss: 63.0682 - val_mean_absolute_error: 63.0682\n",
            "Epoch 757/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5881 - mean_absolute_error: 50.5881 - val_loss: 62.8429 - val_mean_absolute_error: 62.8429\n",
            "Epoch 758/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5875 - mean_absolute_error: 50.5875 - val_loss: 62.9549 - val_mean_absolute_error: 62.9549\n",
            "Epoch 759/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5874 - mean_absolute_error: 50.5874 - val_loss: 63.4321 - val_mean_absolute_error: 63.4321\n",
            "Epoch 760/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5866 - mean_absolute_error: 50.5866 - val_loss: 62.9949 - val_mean_absolute_error: 62.9949\n",
            "Epoch 761/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5867 - mean_absolute_error: 50.5867 - val_loss: 63.5422 - val_mean_absolute_error: 63.5422\n",
            "Epoch 762/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5863 - mean_absolute_error: 50.5863 - val_loss: 63.1141 - val_mean_absolute_error: 63.1141\n",
            "Epoch 763/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5855 - mean_absolute_error: 50.5855 - val_loss: 63.2969 - val_mean_absolute_error: 63.2969\n",
            "Epoch 764/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5852 - mean_absolute_error: 50.5852 - val_loss: 63.1360 - val_mean_absolute_error: 63.1360\n",
            "Epoch 765/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5854 - mean_absolute_error: 50.5854 - val_loss: 63.2643 - val_mean_absolute_error: 63.2643\n",
            "Epoch 766/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5850 - mean_absolute_error: 50.5850 - val_loss: 63.3017 - val_mean_absolute_error: 63.3017\n",
            "Epoch 767/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5846 - mean_absolute_error: 50.5846 - val_loss: 63.4074 - val_mean_absolute_error: 63.4074\n",
            "Epoch 768/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5842 - mean_absolute_error: 50.5842 - val_loss: 63.3738 - val_mean_absolute_error: 63.3738\n",
            "Epoch 769/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5833 - mean_absolute_error: 50.5833 - val_loss: 63.0693 - val_mean_absolute_error: 63.0693\n",
            "Epoch 770/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5837 - mean_absolute_error: 50.5837 - val_loss: 63.3155 - val_mean_absolute_error: 63.3155\n",
            "Epoch 771/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5826 - mean_absolute_error: 50.5826 - val_loss: 63.4282 - val_mean_absolute_error: 63.4282\n",
            "Epoch 772/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5826 - mean_absolute_error: 50.5826 - val_loss: 63.3254 - val_mean_absolute_error: 63.3254\n",
            "Epoch 773/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5823 - mean_absolute_error: 50.5823 - val_loss: 63.1362 - val_mean_absolute_error: 63.1362\n",
            "Epoch 774/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5821 - mean_absolute_error: 50.5821 - val_loss: 63.2554 - val_mean_absolute_error: 63.2554\n",
            "Epoch 775/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5813 - mean_absolute_error: 50.5813 - val_loss: 63.1219 - val_mean_absolute_error: 63.1219\n",
            "Epoch 776/1000\n",
            "769500/769500 [==============================] - 1s 2us/step - loss: 50.5810 - mean_absolute_error: 50.5810 - val_loss: 63.7075 - val_mean_absolute_error: 63.7075\n",
            "Epoch 777/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5808 - mean_absolute_error: 50.5808 - val_loss: 63.4773 - val_mean_absolute_error: 63.4773\n",
            "Epoch 778/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5803 - mean_absolute_error: 50.5803 - val_loss: 63.5293 - val_mean_absolute_error: 63.5293\n",
            "Epoch 779/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5805 - mean_absolute_error: 50.5805 - val_loss: 63.0575 - val_mean_absolute_error: 63.0575\n",
            "Epoch 780/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5799 - mean_absolute_error: 50.5799 - val_loss: 63.4873 - val_mean_absolute_error: 63.4873\n",
            "Epoch 781/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5793 - mean_absolute_error: 50.5793 - val_loss: 63.2274 - val_mean_absolute_error: 63.2274\n",
            "Epoch 782/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5795 - mean_absolute_error: 50.5795 - val_loss: 63.3733 - val_mean_absolute_error: 63.3733\n",
            "Epoch 783/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5787 - mean_absolute_error: 50.5787 - val_loss: 63.3433 - val_mean_absolute_error: 63.3433\n",
            "Epoch 784/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5784 - mean_absolute_error: 50.5784 - val_loss: 63.8307 - val_mean_absolute_error: 63.8307\n",
            "Epoch 785/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5777 - mean_absolute_error: 50.5777 - val_loss: 63.2566 - val_mean_absolute_error: 63.2566\n",
            "Epoch 786/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5782 - mean_absolute_error: 50.5782 - val_loss: 63.3325 - val_mean_absolute_error: 63.3325\n",
            "Epoch 787/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5771 - mean_absolute_error: 50.5771 - val_loss: 63.3468 - val_mean_absolute_error: 63.3468\n",
            "Epoch 788/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5771 - mean_absolute_error: 50.5771 - val_loss: 63.0556 - val_mean_absolute_error: 63.0556\n",
            "Epoch 789/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5766 - mean_absolute_error: 50.5766 - val_loss: 63.2086 - val_mean_absolute_error: 63.2086\n",
            "Epoch 790/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5762 - mean_absolute_error: 50.5762 - val_loss: 63.4624 - val_mean_absolute_error: 63.4624\n",
            "Epoch 791/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5757 - mean_absolute_error: 50.5757 - val_loss: 63.3849 - val_mean_absolute_error: 63.3849\n",
            "Epoch 792/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5756 - mean_absolute_error: 50.5756 - val_loss: 63.2960 - val_mean_absolute_error: 63.2960\n",
            "Epoch 793/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5753 - mean_absolute_error: 50.5753 - val_loss: 62.9952 - val_mean_absolute_error: 62.9952\n",
            "Epoch 794/1000\n",
            "769500/769500 [==============================] - 1s 2us/step - loss: 50.5749 - mean_absolute_error: 50.5749 - val_loss: 63.2405 - val_mean_absolute_error: 63.2405\n",
            "Epoch 795/1000\n",
            "769500/769500 [==============================] - 1s 2us/step - loss: 50.5746 - mean_absolute_error: 50.5746 - val_loss: 63.1302 - val_mean_absolute_error: 63.1302\n",
            "Epoch 796/1000\n",
            "769500/769500 [==============================] - 1s 2us/step - loss: 50.5742 - mean_absolute_error: 50.5742 - val_loss: 63.1320 - val_mean_absolute_error: 63.1320\n",
            "Epoch 797/1000\n",
            "769500/769500 [==============================] - 1s 2us/step - loss: 50.5739 - mean_absolute_error: 50.5739 - val_loss: 63.4357 - val_mean_absolute_error: 63.4357\n",
            "Epoch 798/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5738 - mean_absolute_error: 50.5738 - val_loss: 63.3089 - val_mean_absolute_error: 63.3089\n",
            "Epoch 799/1000\n",
            "769500/769500 [==============================] - 1s 2us/step - loss: 50.5735 - mean_absolute_error: 50.5735 - val_loss: 62.7010 - val_mean_absolute_error: 62.7010\n",
            "Epoch 800/1000\n",
            "769500/769500 [==============================] - 1s 2us/step - loss: 50.5730 - mean_absolute_error: 50.5730 - val_loss: 63.0356 - val_mean_absolute_error: 63.0356\n",
            "Epoch 801/1000\n",
            "769500/769500 [==============================] - 1s 2us/step - loss: 50.5727 - mean_absolute_error: 50.5727 - val_loss: 63.3356 - val_mean_absolute_error: 63.3356\n",
            "Epoch 802/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5722 - mean_absolute_error: 50.5722 - val_loss: 63.3009 - val_mean_absolute_error: 63.3009\n",
            "Epoch 803/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5722 - mean_absolute_error: 50.5722 - val_loss: 63.2496 - val_mean_absolute_error: 63.2496\n",
            "Epoch 804/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5716 - mean_absolute_error: 50.5716 - val_loss: 63.4690 - val_mean_absolute_error: 63.4690\n",
            "Epoch 805/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5709 - mean_absolute_error: 50.5709 - val_loss: 63.1415 - val_mean_absolute_error: 63.1415\n",
            "Epoch 806/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5713 - mean_absolute_error: 50.5713 - val_loss: 63.3812 - val_mean_absolute_error: 63.3812\n",
            "Epoch 807/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5706 - mean_absolute_error: 50.5706 - val_loss: 63.2146 - val_mean_absolute_error: 63.2146\n",
            "Epoch 808/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5701 - mean_absolute_error: 50.5701 - val_loss: 63.4053 - val_mean_absolute_error: 63.4053\n",
            "Epoch 809/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5700 - mean_absolute_error: 50.5700 - val_loss: 63.5365 - val_mean_absolute_error: 63.5365\n",
            "Epoch 810/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5698 - mean_absolute_error: 50.5698 - val_loss: 63.3753 - val_mean_absolute_error: 63.3753\n",
            "Epoch 811/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5693 - mean_absolute_error: 50.5693 - val_loss: 63.3113 - val_mean_absolute_error: 63.3113\n",
            "Epoch 812/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5690 - mean_absolute_error: 50.5690 - val_loss: 63.0336 - val_mean_absolute_error: 63.0336\n",
            "Epoch 813/1000\n",
            "769500/769500 [==============================] - 1s 2us/step - loss: 50.5683 - mean_absolute_error: 50.5683 - val_loss: 63.3496 - val_mean_absolute_error: 63.3496\n",
            "Epoch 814/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5682 - mean_absolute_error: 50.5682 - val_loss: 63.2808 - val_mean_absolute_error: 63.2808\n",
            "Epoch 815/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5677 - mean_absolute_error: 50.5677 - val_loss: 63.1760 - val_mean_absolute_error: 63.1760\n",
            "Epoch 816/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5674 - mean_absolute_error: 50.5674 - val_loss: 63.0762 - val_mean_absolute_error: 63.0762\n",
            "Epoch 817/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5671 - mean_absolute_error: 50.5671 - val_loss: 63.1138 - val_mean_absolute_error: 63.1138\n",
            "Epoch 818/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5666 - mean_absolute_error: 50.5666 - val_loss: 63.0050 - val_mean_absolute_error: 63.0050\n",
            "Epoch 819/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5664 - mean_absolute_error: 50.5664 - val_loss: 63.1745 - val_mean_absolute_error: 63.1745\n",
            "Epoch 820/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5660 - mean_absolute_error: 50.5660 - val_loss: 63.2384 - val_mean_absolute_error: 63.2384\n",
            "Epoch 821/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5657 - mean_absolute_error: 50.5657 - val_loss: 63.2448 - val_mean_absolute_error: 63.2448\n",
            "Epoch 822/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5658 - mean_absolute_error: 50.5658 - val_loss: 63.5485 - val_mean_absolute_error: 63.5485\n",
            "Epoch 823/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5654 - mean_absolute_error: 50.5654 - val_loss: 63.2115 - val_mean_absolute_error: 63.2115\n",
            "Epoch 824/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5651 - mean_absolute_error: 50.5651 - val_loss: 63.1680 - val_mean_absolute_error: 63.1680\n",
            "Epoch 825/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5643 - mean_absolute_error: 50.5643 - val_loss: 63.1166 - val_mean_absolute_error: 63.1166\n",
            "Epoch 826/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5643 - mean_absolute_error: 50.5643 - val_loss: 63.3561 - val_mean_absolute_error: 63.3561\n",
            "Epoch 827/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5639 - mean_absolute_error: 50.5639 - val_loss: 63.2315 - val_mean_absolute_error: 63.2315\n",
            "Epoch 828/1000\n",
            "769500/769500 [==============================] - 1s 2us/step - loss: 50.5632 - mean_absolute_error: 50.5632 - val_loss: 63.2099 - val_mean_absolute_error: 63.2099\n",
            "Epoch 829/1000\n",
            "769500/769500 [==============================] - 1s 2us/step - loss: 50.5630 - mean_absolute_error: 50.5630 - val_loss: 62.9149 - val_mean_absolute_error: 62.9149\n",
            "Epoch 830/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5630 - mean_absolute_error: 50.5630 - val_loss: 63.1509 - val_mean_absolute_error: 63.1509\n",
            "Epoch 831/1000\n",
            "769500/769500 [==============================] - 1s 2us/step - loss: 50.5627 - mean_absolute_error: 50.5627 - val_loss: 63.0600 - val_mean_absolute_error: 63.0600\n",
            "Epoch 832/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5626 - mean_absolute_error: 50.5626 - val_loss: 63.0710 - val_mean_absolute_error: 63.0710\n",
            "Epoch 833/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5618 - mean_absolute_error: 50.5618 - val_loss: 63.1850 - val_mean_absolute_error: 63.1850\n",
            "Epoch 834/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5613 - mean_absolute_error: 50.5613 - val_loss: 63.0691 - val_mean_absolute_error: 63.0691\n",
            "Epoch 835/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5610 - mean_absolute_error: 50.5610 - val_loss: 63.0697 - val_mean_absolute_error: 63.0697\n",
            "Epoch 836/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5606 - mean_absolute_error: 50.5606 - val_loss: 63.1748 - val_mean_absolute_error: 63.1748\n",
            "Epoch 837/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5607 - mean_absolute_error: 50.5607 - val_loss: 63.1430 - val_mean_absolute_error: 63.1430\n",
            "Epoch 838/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5604 - mean_absolute_error: 50.5604 - val_loss: 63.1979 - val_mean_absolute_error: 63.1979\n",
            "Epoch 839/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5600 - mean_absolute_error: 50.5600 - val_loss: 63.3931 - val_mean_absolute_error: 63.3931\n",
            "Epoch 840/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5592 - mean_absolute_error: 50.5592 - val_loss: 63.0017 - val_mean_absolute_error: 63.0017\n",
            "Epoch 841/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5590 - mean_absolute_error: 50.5590 - val_loss: 63.3916 - val_mean_absolute_error: 63.3916\n",
            "Epoch 842/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5590 - mean_absolute_error: 50.5590 - val_loss: 63.0255 - val_mean_absolute_error: 63.0255\n",
            "Epoch 843/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5584 - mean_absolute_error: 50.5584 - val_loss: 63.5610 - val_mean_absolute_error: 63.5610\n",
            "Epoch 844/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5582 - mean_absolute_error: 50.5582 - val_loss: 63.2354 - val_mean_absolute_error: 63.2354\n",
            "Epoch 845/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5577 - mean_absolute_error: 50.5577 - val_loss: 63.0550 - val_mean_absolute_error: 63.0550\n",
            "Epoch 846/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5578 - mean_absolute_error: 50.5578 - val_loss: 63.3517 - val_mean_absolute_error: 63.3517\n",
            "Epoch 847/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5569 - mean_absolute_error: 50.5569 - val_loss: 63.2105 - val_mean_absolute_error: 63.2105\n",
            "Epoch 848/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5568 - mean_absolute_error: 50.5568 - val_loss: 62.8474 - val_mean_absolute_error: 62.8474\n",
            "Epoch 849/1000\n",
            "769500/769500 [==============================] - 1s 2us/step - loss: 50.5565 - mean_absolute_error: 50.5565 - val_loss: 63.2708 - val_mean_absolute_error: 63.2708\n",
            "Epoch 850/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5562 - mean_absolute_error: 50.5562 - val_loss: 63.0419 - val_mean_absolute_error: 63.0419\n",
            "Epoch 851/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5554 - mean_absolute_error: 50.5554 - val_loss: 63.0753 - val_mean_absolute_error: 63.0753\n",
            "Epoch 852/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5559 - mean_absolute_error: 50.5559 - val_loss: 63.1885 - val_mean_absolute_error: 63.1885\n",
            "Epoch 853/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5555 - mean_absolute_error: 50.5555 - val_loss: 63.0228 - val_mean_absolute_error: 63.0228\n",
            "Epoch 854/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5548 - mean_absolute_error: 50.5548 - val_loss: 63.1662 - val_mean_absolute_error: 63.1662\n",
            "Epoch 855/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5546 - mean_absolute_error: 50.5546 - val_loss: 63.4402 - val_mean_absolute_error: 63.4402\n",
            "Epoch 856/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5539 - mean_absolute_error: 50.5539 - val_loss: 63.4039 - val_mean_absolute_error: 63.4039\n",
            "Epoch 857/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5538 - mean_absolute_error: 50.5538 - val_loss: 63.1592 - val_mean_absolute_error: 63.1592\n",
            "Epoch 858/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5534 - mean_absolute_error: 50.5534 - val_loss: 63.3510 - val_mean_absolute_error: 63.3510\n",
            "Epoch 859/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5535 - mean_absolute_error: 50.5535 - val_loss: 63.0693 - val_mean_absolute_error: 63.0693\n",
            "Epoch 860/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5527 - mean_absolute_error: 50.5527 - val_loss: 63.2335 - val_mean_absolute_error: 63.2335\n",
            "Epoch 861/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5529 - mean_absolute_error: 50.5529 - val_loss: 63.1439 - val_mean_absolute_error: 63.1439\n",
            "Epoch 862/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5520 - mean_absolute_error: 50.5520 - val_loss: 62.8746 - val_mean_absolute_error: 62.8746\n",
            "Epoch 863/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5519 - mean_absolute_error: 50.5519 - val_loss: 63.3542 - val_mean_absolute_error: 63.3542\n",
            "Epoch 864/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5515 - mean_absolute_error: 50.5515 - val_loss: 63.1702 - val_mean_absolute_error: 63.1702\n",
            "Epoch 865/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5509 - mean_absolute_error: 50.5509 - val_loss: 63.1536 - val_mean_absolute_error: 63.1536\n",
            "Epoch 866/1000\n",
            "769500/769500 [==============================] - 1s 2us/step - loss: 50.5505 - mean_absolute_error: 50.5505 - val_loss: 63.1642 - val_mean_absolute_error: 63.1642\n",
            "Epoch 867/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5504 - mean_absolute_error: 50.5504 - val_loss: 63.2590 - val_mean_absolute_error: 63.2590\n",
            "Epoch 868/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5501 - mean_absolute_error: 50.5501 - val_loss: 63.7474 - val_mean_absolute_error: 63.7474\n",
            "Epoch 869/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5499 - mean_absolute_error: 50.5499 - val_loss: 63.3183 - val_mean_absolute_error: 63.3183\n",
            "Epoch 870/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5494 - mean_absolute_error: 50.5494 - val_loss: 63.4121 - val_mean_absolute_error: 63.4121\n",
            "Epoch 871/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5491 - mean_absolute_error: 50.5491 - val_loss: 63.2401 - val_mean_absolute_error: 63.2401\n",
            "Epoch 872/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5485 - mean_absolute_error: 50.5485 - val_loss: 63.1536 - val_mean_absolute_error: 63.1536\n",
            "Epoch 873/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5484 - mean_absolute_error: 50.5484 - val_loss: 62.8188 - val_mean_absolute_error: 62.8188\n",
            "Epoch 874/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5478 - mean_absolute_error: 50.5478 - val_loss: 63.2845 - val_mean_absolute_error: 63.2845\n",
            "Epoch 875/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5480 - mean_absolute_error: 50.5480 - val_loss: 63.1060 - val_mean_absolute_error: 63.1060\n",
            "Epoch 876/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5470 - mean_absolute_error: 50.5470 - val_loss: 63.0568 - val_mean_absolute_error: 63.0568\n",
            "Epoch 877/1000\n",
            "769500/769500 [==============================] - 1s 2us/step - loss: 50.5471 - mean_absolute_error: 50.5471 - val_loss: 62.7512 - val_mean_absolute_error: 62.7512\n",
            "Epoch 878/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5467 - mean_absolute_error: 50.5467 - val_loss: 63.1256 - val_mean_absolute_error: 63.1256\n",
            "Epoch 879/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5463 - mean_absolute_error: 50.5463 - val_loss: 63.3527 - val_mean_absolute_error: 63.3527\n",
            "Epoch 880/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5461 - mean_absolute_error: 50.5461 - val_loss: 63.0472 - val_mean_absolute_error: 63.0472\n",
            "Epoch 881/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5453 - mean_absolute_error: 50.5453 - val_loss: 63.1352 - val_mean_absolute_error: 63.1352\n",
            "Epoch 882/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5454 - mean_absolute_error: 50.5454 - val_loss: 62.8725 - val_mean_absolute_error: 62.8725\n",
            "Epoch 883/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5452 - mean_absolute_error: 50.5452 - val_loss: 63.3386 - val_mean_absolute_error: 63.3386\n",
            "Epoch 884/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5449 - mean_absolute_error: 50.5449 - val_loss: 63.1557 - val_mean_absolute_error: 63.1557\n",
            "Epoch 885/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5443 - mean_absolute_error: 50.5443 - val_loss: 62.8842 - val_mean_absolute_error: 62.8842\n",
            "Epoch 886/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5442 - mean_absolute_error: 50.5442 - val_loss: 63.0494 - val_mean_absolute_error: 63.0494\n",
            "Epoch 887/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5438 - mean_absolute_error: 50.5438 - val_loss: 63.0738 - val_mean_absolute_error: 63.0738\n",
            "Epoch 888/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5431 - mean_absolute_error: 50.5431 - val_loss: 62.8406 - val_mean_absolute_error: 62.8406\n",
            "Epoch 889/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5432 - mean_absolute_error: 50.5432 - val_loss: 62.8875 - val_mean_absolute_error: 62.8875\n",
            "Epoch 890/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5428 - mean_absolute_error: 50.5428 - val_loss: 63.0940 - val_mean_absolute_error: 63.0940\n",
            "Epoch 891/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5422 - mean_absolute_error: 50.5422 - val_loss: 62.9831 - val_mean_absolute_error: 62.9831\n",
            "Epoch 892/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5419 - mean_absolute_error: 50.5419 - val_loss: 62.7963 - val_mean_absolute_error: 62.7963\n",
            "Epoch 893/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5415 - mean_absolute_error: 50.5415 - val_loss: 63.5843 - val_mean_absolute_error: 63.5843\n",
            "Epoch 894/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5413 - mean_absolute_error: 50.5413 - val_loss: 63.2469 - val_mean_absolute_error: 63.2469\n",
            "Epoch 895/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5405 - mean_absolute_error: 50.5405 - val_loss: 63.0486 - val_mean_absolute_error: 63.0486\n",
            "Epoch 896/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5406 - mean_absolute_error: 50.5406 - val_loss: 63.0975 - val_mean_absolute_error: 63.0975\n",
            "Epoch 897/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5400 - mean_absolute_error: 50.5400 - val_loss: 62.9551 - val_mean_absolute_error: 62.9551\n",
            "Epoch 898/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5402 - mean_absolute_error: 50.5402 - val_loss: 62.8916 - val_mean_absolute_error: 62.8916\n",
            "Epoch 899/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5393 - mean_absolute_error: 50.5393 - val_loss: 63.4423 - val_mean_absolute_error: 63.4423\n",
            "Epoch 900/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5390 - mean_absolute_error: 50.5390 - val_loss: 63.1868 - val_mean_absolute_error: 63.1868\n",
            "Epoch 901/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5390 - mean_absolute_error: 50.5390 - val_loss: 62.7632 - val_mean_absolute_error: 62.7632\n",
            "Epoch 902/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5387 - mean_absolute_error: 50.5387 - val_loss: 62.9914 - val_mean_absolute_error: 62.9914\n",
            "Epoch 903/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5377 - mean_absolute_error: 50.5377 - val_loss: 63.4837 - val_mean_absolute_error: 63.4837\n",
            "Epoch 904/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5372 - mean_absolute_error: 50.5372 - val_loss: 63.1512 - val_mean_absolute_error: 63.1512\n",
            "Epoch 905/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5373 - mean_absolute_error: 50.5373 - val_loss: 63.2245 - val_mean_absolute_error: 63.2245\n",
            "Epoch 906/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5372 - mean_absolute_error: 50.5372 - val_loss: 63.1028 - val_mean_absolute_error: 63.1028\n",
            "Epoch 907/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5366 - mean_absolute_error: 50.5366 - val_loss: 63.1291 - val_mean_absolute_error: 63.1291\n",
            "Epoch 908/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5358 - mean_absolute_error: 50.5358 - val_loss: 63.3067 - val_mean_absolute_error: 63.3067\n",
            "Epoch 909/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5357 - mean_absolute_error: 50.5357 - val_loss: 63.2345 - val_mean_absolute_error: 63.2345\n",
            "Epoch 910/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5358 - mean_absolute_error: 50.5358 - val_loss: 63.1351 - val_mean_absolute_error: 63.1351\n",
            "Epoch 911/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5346 - mean_absolute_error: 50.5346 - val_loss: 63.2692 - val_mean_absolute_error: 63.2692\n",
            "Epoch 912/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5347 - mean_absolute_error: 50.5347 - val_loss: 63.0598 - val_mean_absolute_error: 63.0598\n",
            "Epoch 913/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5344 - mean_absolute_error: 50.5344 - val_loss: 62.5917 - val_mean_absolute_error: 62.5917\n",
            "Epoch 914/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5341 - mean_absolute_error: 50.5341 - val_loss: 63.2049 - val_mean_absolute_error: 63.2049\n",
            "Epoch 915/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5336 - mean_absolute_error: 50.5336 - val_loss: 62.8759 - val_mean_absolute_error: 62.8759\n",
            "Epoch 916/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5326 - mean_absolute_error: 50.5326 - val_loss: 62.7421 - val_mean_absolute_error: 62.7421\n",
            "Epoch 917/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5332 - mean_absolute_error: 50.5332 - val_loss: 62.8666 - val_mean_absolute_error: 62.8666\n",
            "Epoch 918/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5325 - mean_absolute_error: 50.5325 - val_loss: 63.2432 - val_mean_absolute_error: 63.2432\n",
            "Epoch 919/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5318 - mean_absolute_error: 50.5318 - val_loss: 62.9925 - val_mean_absolute_error: 62.9925\n",
            "Epoch 920/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5318 - mean_absolute_error: 50.5318 - val_loss: 63.2576 - val_mean_absolute_error: 63.2576\n",
            "Epoch 921/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5312 - mean_absolute_error: 50.5312 - val_loss: 63.2306 - val_mean_absolute_error: 63.2306\n",
            "Epoch 922/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5313 - mean_absolute_error: 50.5313 - val_loss: 63.0218 - val_mean_absolute_error: 63.0218\n",
            "Epoch 923/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5307 - mean_absolute_error: 50.5307 - val_loss: 63.2010 - val_mean_absolute_error: 63.2010\n",
            "Epoch 924/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5300 - mean_absolute_error: 50.5300 - val_loss: 63.2753 - val_mean_absolute_error: 63.2753\n",
            "Epoch 925/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5296 - mean_absolute_error: 50.5296 - val_loss: 63.0590 - val_mean_absolute_error: 63.0590\n",
            "Epoch 926/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5297 - mean_absolute_error: 50.5297 - val_loss: 63.2281 - val_mean_absolute_error: 63.2281\n",
            "Epoch 927/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5294 - mean_absolute_error: 50.5294 - val_loss: 63.2614 - val_mean_absolute_error: 63.2614\n",
            "Epoch 928/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5289 - mean_absolute_error: 50.5289 - val_loss: 63.1621 - val_mean_absolute_error: 63.1621\n",
            "Epoch 929/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5282 - mean_absolute_error: 50.5282 - val_loss: 63.0408 - val_mean_absolute_error: 63.0408\n",
            "Epoch 930/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5286 - mean_absolute_error: 50.5286 - val_loss: 63.1831 - val_mean_absolute_error: 63.1831\n",
            "Epoch 931/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5277 - mean_absolute_error: 50.5277 - val_loss: 62.9625 - val_mean_absolute_error: 62.9625\n",
            "Epoch 932/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5271 - mean_absolute_error: 50.5271 - val_loss: 63.0276 - val_mean_absolute_error: 63.0276\n",
            "Epoch 933/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5272 - mean_absolute_error: 50.5272 - val_loss: 62.9797 - val_mean_absolute_error: 62.9797\n",
            "Epoch 934/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5264 - mean_absolute_error: 50.5264 - val_loss: 63.1441 - val_mean_absolute_error: 63.1441\n",
            "Epoch 935/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5263 - mean_absolute_error: 50.5263 - val_loss: 63.0096 - val_mean_absolute_error: 63.0096\n",
            "Epoch 936/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5260 - mean_absolute_error: 50.5260 - val_loss: 62.8302 - val_mean_absolute_error: 62.8302\n",
            "Epoch 937/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5256 - mean_absolute_error: 50.5256 - val_loss: 62.9862 - val_mean_absolute_error: 62.9862\n",
            "Epoch 938/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5251 - mean_absolute_error: 50.5251 - val_loss: 63.2239 - val_mean_absolute_error: 63.2239\n",
            "Epoch 939/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5246 - mean_absolute_error: 50.5246 - val_loss: 63.0820 - val_mean_absolute_error: 63.0820\n",
            "Epoch 940/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5246 - mean_absolute_error: 50.5246 - val_loss: 62.8971 - val_mean_absolute_error: 62.8971\n",
            "Epoch 941/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5242 - mean_absolute_error: 50.5242 - val_loss: 63.0233 - val_mean_absolute_error: 63.0233\n",
            "Epoch 942/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5238 - mean_absolute_error: 50.5238 - val_loss: 62.9932 - val_mean_absolute_error: 62.9932\n",
            "Epoch 943/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5237 - mean_absolute_error: 50.5237 - val_loss: 62.8080 - val_mean_absolute_error: 62.8080\n",
            "Epoch 944/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5231 - mean_absolute_error: 50.5231 - val_loss: 63.0643 - val_mean_absolute_error: 63.0643\n",
            "Epoch 945/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5229 - mean_absolute_error: 50.5229 - val_loss: 63.0474 - val_mean_absolute_error: 63.0474\n",
            "Epoch 946/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5223 - mean_absolute_error: 50.5223 - val_loss: 62.8308 - val_mean_absolute_error: 62.8308\n",
            "Epoch 947/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5220 - mean_absolute_error: 50.5220 - val_loss: 63.1397 - val_mean_absolute_error: 63.1397\n",
            "Epoch 948/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5221 - mean_absolute_error: 50.5221 - val_loss: 63.1896 - val_mean_absolute_error: 63.1896\n",
            "Epoch 949/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5215 - mean_absolute_error: 50.5215 - val_loss: 63.0319 - val_mean_absolute_error: 63.0319\n",
            "Epoch 950/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5214 - mean_absolute_error: 50.5214 - val_loss: 63.0700 - val_mean_absolute_error: 63.0700\n",
            "Epoch 951/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5208 - mean_absolute_error: 50.5208 - val_loss: 63.2233 - val_mean_absolute_error: 63.2233\n",
            "Epoch 952/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5205 - mean_absolute_error: 50.5205 - val_loss: 63.1328 - val_mean_absolute_error: 63.1328\n",
            "Epoch 953/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5203 - mean_absolute_error: 50.5203 - val_loss: 63.0006 - val_mean_absolute_error: 63.0006\n",
            "Epoch 954/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5201 - mean_absolute_error: 50.5201 - val_loss: 63.0658 - val_mean_absolute_error: 63.0658\n",
            "Epoch 955/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5196 - mean_absolute_error: 50.5196 - val_loss: 62.9879 - val_mean_absolute_error: 62.9879\n",
            "Epoch 956/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5190 - mean_absolute_error: 50.5190 - val_loss: 63.2905 - val_mean_absolute_error: 63.2905\n",
            "Epoch 957/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5190 - mean_absolute_error: 50.5190 - val_loss: 62.9739 - val_mean_absolute_error: 62.9739\n",
            "Epoch 958/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5184 - mean_absolute_error: 50.5184 - val_loss: 63.0776 - val_mean_absolute_error: 63.0776\n",
            "Epoch 959/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5179 - mean_absolute_error: 50.5179 - val_loss: 63.2080 - val_mean_absolute_error: 63.2080\n",
            "Epoch 960/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5177 - mean_absolute_error: 50.5177 - val_loss: 63.1838 - val_mean_absolute_error: 63.1838\n",
            "Epoch 961/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5176 - mean_absolute_error: 50.5176 - val_loss: 63.1142 - val_mean_absolute_error: 63.1142\n",
            "Epoch 962/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5171 - mean_absolute_error: 50.5171 - val_loss: 63.2092 - val_mean_absolute_error: 63.2092\n",
            "Epoch 963/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5166 - mean_absolute_error: 50.5166 - val_loss: 62.6023 - val_mean_absolute_error: 62.6023\n",
            "Epoch 964/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5164 - mean_absolute_error: 50.5164 - val_loss: 63.0643 - val_mean_absolute_error: 63.0643\n",
            "Epoch 965/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5161 - mean_absolute_error: 50.5161 - val_loss: 62.7401 - val_mean_absolute_error: 62.7401\n",
            "Epoch 966/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5159 - mean_absolute_error: 50.5159 - val_loss: 63.0440 - val_mean_absolute_error: 63.0440\n",
            "Epoch 967/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5157 - mean_absolute_error: 50.5157 - val_loss: 63.2873 - val_mean_absolute_error: 63.2873\n",
            "Epoch 968/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5149 - mean_absolute_error: 50.5149 - val_loss: 62.7811 - val_mean_absolute_error: 62.7811\n",
            "Epoch 969/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5149 - mean_absolute_error: 50.5149 - val_loss: 62.8809 - val_mean_absolute_error: 62.8809\n",
            "Epoch 970/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5146 - mean_absolute_error: 50.5146 - val_loss: 63.4054 - val_mean_absolute_error: 63.4054\n",
            "Epoch 971/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5141 - mean_absolute_error: 50.5141 - val_loss: 63.1074 - val_mean_absolute_error: 63.1074\n",
            "Epoch 972/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5140 - mean_absolute_error: 50.5140 - val_loss: 63.0262 - val_mean_absolute_error: 63.0262\n",
            "Epoch 973/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5134 - mean_absolute_error: 50.5134 - val_loss: 62.6792 - val_mean_absolute_error: 62.6792\n",
            "Epoch 974/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5134 - mean_absolute_error: 50.5134 - val_loss: 63.2550 - val_mean_absolute_error: 63.2550\n",
            "Epoch 975/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5131 - mean_absolute_error: 50.5131 - val_loss: 63.1716 - val_mean_absolute_error: 63.1716\n",
            "Epoch 976/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5125 - mean_absolute_error: 50.5125 - val_loss: 63.0661 - val_mean_absolute_error: 63.0661\n",
            "Epoch 977/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5124 - mean_absolute_error: 50.5124 - val_loss: 63.1785 - val_mean_absolute_error: 63.1785\n",
            "Epoch 978/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5118 - mean_absolute_error: 50.5118 - val_loss: 63.1963 - val_mean_absolute_error: 63.1963\n",
            "Epoch 979/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5119 - mean_absolute_error: 50.5119 - val_loss: 63.2720 - val_mean_absolute_error: 63.2720\n",
            "Epoch 980/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5109 - mean_absolute_error: 50.5109 - val_loss: 62.9484 - val_mean_absolute_error: 62.9484\n",
            "Epoch 981/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5108 - mean_absolute_error: 50.5108 - val_loss: 63.0397 - val_mean_absolute_error: 63.0397\n",
            "Epoch 982/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5108 - mean_absolute_error: 50.5108 - val_loss: 63.3108 - val_mean_absolute_error: 63.3108\n",
            "Epoch 983/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5106 - mean_absolute_error: 50.5106 - val_loss: 62.8244 - val_mean_absolute_error: 62.8244\n",
            "Epoch 984/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5101 - mean_absolute_error: 50.5101 - val_loss: 63.1610 - val_mean_absolute_error: 63.1610\n",
            "Epoch 985/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5098 - mean_absolute_error: 50.5098 - val_loss: 62.6949 - val_mean_absolute_error: 62.6949\n",
            "Epoch 986/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5092 - mean_absolute_error: 50.5092 - val_loss: 63.0972 - val_mean_absolute_error: 63.0972\n",
            "Epoch 987/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5093 - mean_absolute_error: 50.5093 - val_loss: 62.9805 - val_mean_absolute_error: 62.9805\n",
            "Epoch 988/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5088 - mean_absolute_error: 50.5088 - val_loss: 63.3158 - val_mean_absolute_error: 63.3158\n",
            "Epoch 989/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5085 - mean_absolute_error: 50.5085 - val_loss: 63.1636 - val_mean_absolute_error: 63.1636\n",
            "Epoch 990/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5083 - mean_absolute_error: 50.5083 - val_loss: 63.1366 - val_mean_absolute_error: 63.1366\n",
            "Epoch 991/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5078 - mean_absolute_error: 50.5078 - val_loss: 62.8725 - val_mean_absolute_error: 62.8725\n",
            "Epoch 992/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5074 - mean_absolute_error: 50.5074 - val_loss: 62.9083 - val_mean_absolute_error: 62.9083\n",
            "Epoch 993/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5072 - mean_absolute_error: 50.5072 - val_loss: 62.9487 - val_mean_absolute_error: 62.9487\n",
            "Epoch 994/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5072 - mean_absolute_error: 50.5072 - val_loss: 63.2876 - val_mean_absolute_error: 63.2876\n",
            "Epoch 995/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5065 - mean_absolute_error: 50.5065 - val_loss: 62.8541 - val_mean_absolute_error: 62.8541\n",
            "Epoch 996/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5064 - mean_absolute_error: 50.5064 - val_loss: 62.9191 - val_mean_absolute_error: 62.9191\n",
            "Epoch 997/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5058 - mean_absolute_error: 50.5058 - val_loss: 63.1459 - val_mean_absolute_error: 63.1459\n",
            "Epoch 998/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5058 - mean_absolute_error: 50.5058 - val_loss: 63.1858 - val_mean_absolute_error: 63.1858\n",
            "Epoch 999/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5056 - mean_absolute_error: 50.5056 - val_loss: 62.7791 - val_mean_absolute_error: 62.7791\n",
            "Epoch 1000/1000\n",
            "769500/769500 [==============================] - 1s 1us/step - loss: 50.5051 - mean_absolute_error: 50.5051 - val_loss: 63.3151 - val_mean_absolute_error: 63.3151\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0ZjVIbwHMCA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#예측값을 생성합니다.\n",
        "pred_test = model.predict(test_X_pca)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvGoomf4MRrD",
        "colab_type": "code",
        "outputId": "9c856c28-8d87-4752-fc91-76cd51aa483a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd /content/gdrive/My Drive/semiconductor"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/semiconductor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjwvRcclUL_2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ce86a4e5-0261-4162-a8b7-883641613eaf"
      },
      "source": [
        "!ls \"/content/gdrive/My Drive/semiconductor\""
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "submission.csv\ttest.csv  train.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqXnLhTLHME3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#submission 파일을 생성합니다.\n",
        "sample_sub = pd.read_csv('submission.csv', index_col=0)\n",
        "submission = sample_sub+pred_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6tEms-fMRAr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission.to_csv('200115_submission2.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOaGHrMBQnmb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "9b98c7ff-817f-4006-838c-0efa7aa95bc7"
      },
      "source": [
        " !ls \"/content/gdrive/My Drive/semiconductor\""
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "200115_submission1.csv\tsubmission.csv\ttrain.csv\n",
            "200115_submission2.csv\ttest.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGgzAFIhU2MM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}